{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "save_path = \"C:/data/result/saved_dataset\"\n",
    "def load_dataset(save_path):\n",
    "    \"\"\"\n",
    "    从指定路径加载 TensorFlow 数据集。\n",
    "    \n",
    "    Args:\n",
    "        save_path: 数据集保存路径。\n",
    "    Returns:\n",
    "        加载的 tf.data.Dataset 对象。\n",
    "    \"\"\"\n",
    "    dataset = tf.data.experimental.load(save_path)\n",
    "    print(f\"数据集已从 {save_path} 加载\")\n",
    "    return dataset\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(save_path)\n",
    "\n",
    "# 假设 dataset 是已经处理好的 tf.data.Dataset 对象\n",
    "# 将 dataset 分为训练集和验证集\n",
    "train_split = 0.8  # 80% 数据用于训练\n",
    "val_split = 1 - train_split\n",
    "\n",
    "# 获取总样本数\n",
    "total_samples = len(list(dataset))\n",
    "train_size = int(total_samples * train_split)\n",
    "\n",
    "# 分割数据集\n",
    "train_ds = dataset.take(train_size)\n",
    "val_ds = dataset.skip(train_size)\n",
    "\n",
    "# 配置训练和验证集\n",
    "train_ds = train_ds.shuffle(buffer_size=1000).batch(8).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(8).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "del dataset\n",
    "import gc\n",
    "gc.collect()  # 强制进行垃圾回收"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\"训练集标签分布:\", np.unique(train_ds, return_counts=True))\n",
    "print(\"验证集标签分布:\", np.unique(val_ds, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20, 224, 224, 3)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " hardwired_layer (HardwiredL  (None, 20, 224, 224, 7)  0         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " conv2_plus1d (Conv2Plus1D)  (None, 20, 224, 224, 16)  6288      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 20, 224, 224, 16)  64       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 20, 224, 224, 16)  0         \n",
      "                                                                 \n",
      " resize_video (ResizeVideo)  (None, 20, 112, 112, 16)  0         \n",
      "                                                                 \n",
      " residual_main (ResidualMain  (None, 20, 112, 112, 16)  6272     \n",
      " )                                                               \n",
      "                                                                 \n",
      " resize_video_1 (ResizeVideo  (None, 20, 56, 56, 16)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_main_1 (ResidualMa  (None, 20, 56, 56, 32)   20224     \n",
      " in)                                                             \n",
      "                                                                 \n",
      " resize_video_2 (ResizeVideo  (None, 20, 28, 28, 32)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2_plus1d_5 (Conv2Plus1D  (None, 20, 28, 28, 32)   28736     \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 20, 28, 28, 32)   128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 20, 28, 28, 32)    0         \n",
      "                                                                 \n",
      " residual_main_2 (ResidualMa  (None, 20, 28, 28, 64)   80384     \n",
      " in)                                                             \n",
      "                                                                 \n",
      " resize_video_3 (ResizeVideo  (None, 20, 14, 14, 64)   0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_main_3 (ResidualMa  (None, 20, 14, 14, 128)  320512    \n",
      " in)                                                             \n",
      "                                                                 \n",
      " global_average_pooling3d (G  (None, 128)              0         \n",
      " lobalAveragePooling3D)                                          \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 15)                1935      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 464,543\n",
      "Trainable params: 464,447\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import einops\n",
    "# 启用 XLA\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# 检查 GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for gpu in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(f\"Using GPU: {physical_devices}\")\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")\n",
    "\n",
    "# 定义自定义的硬连线层\n",
    "class HardwiredLayer(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(HardwiredLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, video):\n",
    "        \"\"\"\n",
    "        从每个视频帧提取灰度、梯度等特征，拼接成一个张量。\n",
    "        \"\"\"\n",
    "        # 假设 'video' 的形状为 (batch, time, height, width, channels)\n",
    "        batch, time, height, width, channels = video.shape\n",
    "\n",
    "        # 将视频的时间维度拆分开来，逐帧处理\n",
    "        def process_frame(frame):\n",
    "            # 灰度图：将每帧转化为灰度图（3通道转1通道）\n",
    "            gray_frame = tf.image.rgb_to_grayscale(frame)\n",
    "\n",
    "            # 计算x, y方向的梯度\n",
    "            grad_x = tf.image.sobel_edges(frame)[:,:,:,:,0]  # sobel梯度计算，提取x方向的梯度\n",
    "            grad_y = tf.image.sobel_edges(frame)[:,:,:,:,1]  # sobel梯度计算，提取y方向的梯度\n",
    "\n",
    "            # 拼接特征（灰度 + x方向梯度 + y方向梯度）\n",
    "            features = tf.concat([gray_frame, grad_x, grad_y], axis=-1)  # 在最后一个通道维度拼接\n",
    "            return features\n",
    "\n",
    "        # 逐帧处理所有时间步\n",
    "        video_features = tf.map_fn(process_frame, video, dtype=tf.float32)\n",
    "\n",
    "        return video_features\n",
    "\n",
    "\n",
    "# 定义3D卷积层，考虑时间序列\n",
    "class Conv2Plus1D(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seq = keras.Sequential([  \n",
    "            # 空间维度卷积\n",
    "            layers.Conv3D(filters=filters,\n",
    "                          kernel_size=(1, kernel_size[1], kernel_size[2]),  # 只对空间进行卷积\n",
    "                          padding=padding),\n",
    "            # 时间维度卷积\n",
    "            layers.Conv3D(filters=filters, \n",
    "                          kernel_size=(kernel_size[0], 1, 1),  # 只对时间维度进行卷积\n",
    "                          padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# 定义残差模块\n",
    "class ResidualMain(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.seq = keras.Sequential([\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# 定义视频尺寸调整层\n",
    "class ResizeVideo(keras.layers.Layer):\n",
    "    def __init__(self, height, width, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "# 定义模型\n",
    "def build_model(input_shape):\n",
    "    input = layers.Input(shape=input_shape)  # 输入层，形状为 (时间步数, 高度, 宽度, 通道数)\n",
    "    x = input\n",
    "\n",
    "    # 第一层：硬连线层，提取视频帧特征（灰度 + 梯度）\n",
    "    x = HardwiredLayer()(x)\n",
    "\n",
    "    # 第一层卷积：空间 + 时间的卷积\n",
    "    x = Conv2Plus1D(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = ResizeVideo(HEIGHT//2, WIDTH//2)(x)\n",
    "\n",
    "    # 第一个残差块\n",
    "    x = ResidualMain(filters=16, kernel_size=(3, 3, 3))(x)\n",
    "    x = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)\n",
    "\n",
    "   \n",
    "\n",
    "    # 第二个残差块\n",
    "    x = ResidualMain(filters=32, kernel_size=(3, 3, 3))(x)\n",
    "    x = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)\n",
    "     # 第一个时间卷积层：进一步提取时间特征\n",
    "    x = Conv2Plus1D(filters=32, kernel_size=(3, 5, 5), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # 第三个残差块\n",
    "    x = ResidualMain(filters=64, kernel_size=(3, 3, 3))(x)\n",
    "    x = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)\n",
    "\n",
    "\n",
    "\n",
    "    # 第四个残差块\n",
    "    x = ResidualMain(filters=128, kernel_size=(3, 3, 3))(x)\n",
    "\n",
    "    # 全局平均池化和分类\n",
    "    x = layers.GlobalAveragePooling3D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(15)(x)  # 输出15类分类任务\n",
    "\n",
    "    # 定义模型\n",
    "    model = keras.Model(inputs=input, outputs=x)\n",
    "    return model\n",
    "\n",
    "# 假设高度和宽度为224\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "# 定义输入的形状，假设20帧，每帧224x224的图像，RGB通道\n",
    "input_shape = (20, HEIGHT, WIDTH, 3)\n",
    "\n",
    "# 设置初始学习率\n",
    "initial_learning_rate = 0.0002\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# 使用Adam优化器并设置初始学习率\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "\n",
    "# 定义学习率调整回调\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 监控验证集的损失\n",
    "    factor=0.5,          # 每次衰减的比例\n",
    "    patience=3,          # 若验证集损失在连续3个epoch内不再改善，才衰减学习率\n",
    "    verbose=1            # 打印学习率调整信息\n",
    ")\n",
    "\n",
    "\n",
    "# 构建模型\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 打印模型摘要\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(tf.test.is_gpu_available())\n",
    "# 列出所有物理 GPU 设备\n",
    "print(\"Physical GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',        # 监控的指标，通常选择验证集的损失值（val_loss）\n",
    "    patience=10,                # 允许验证集损失在5个epoch内没有改善\n",
    "    restore_best_weights=True, # 如果训练提前停止，恢复验证集损失最小的模型权重\n",
    "    verbose=1                  # verbose控制输出的详细程度，1表示在停止时输出提示信息\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=50,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[ lr_scheduler,early_stop]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
