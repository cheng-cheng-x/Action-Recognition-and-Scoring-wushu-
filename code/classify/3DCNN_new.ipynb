{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "# 全局路径配置\n",
    "OUTPUT_DIR = \"C:/data/result/scene_detector\"  # 关键帧存放目录\n",
    "TARGET_FRAMES = 20  # 每个视频的关键帧数\n",
    "HEIGHT, WIDTH = 224, 224  # 每帧的大小\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_frames(frame_paths, target_height, target_width, target_frames):\n",
    "    \"\"\"\n",
    "    从帧路径加载关键帧并预处理为固定大小和数量。\n",
    "    \n",
    "    Args:\n",
    "        frame_paths: 帧文件路径列表（按时间顺序）。\n",
    "        target_height: 每帧的目标高度。\n",
    "        target_width: 每帧的目标宽度。\n",
    "        target_frames: 目标帧数。\n",
    "    Returns:\n",
    "        关键帧张量，形状为 (target_frames, height, width, channels)。\n",
    "    \"\"\"\n",
    "    # 加载并调整帧大小\n",
    "    frames = []\n",
    "    for frame_path in sorted(frame_paths):  # 确保按帧序排列\n",
    "        image = Image.open(frame_path)\n",
    "        image = image.resize((target_width, target_height))\n",
    "        frames.append(np.array(image) / 255.0)  # 归一化到 [0, 1]\n",
    "    \n",
    "    # 确保帧数量一致（补齐或裁剪）\n",
    "    if len(frames) > target_frames:\n",
    "        frames = frames[:target_frames]\n",
    "    elif len(frames) < target_frames:\n",
    "        padding = target_frames - len(frames)\n",
    "        frames.extend([np.zeros((target_height, target_width, 3))] * padding)  # 补零帧\n",
    "    \n",
    "    return np.stack(frames, axis=0)\n",
    "def create_dataset_from_frames(output_dir, target_frames, height, width):\n",
    "    \"\"\"\n",
    "    从已存在的关键帧目录构建 TensorFlow 数据集。\n",
    "    \n",
    "    Args:\n",
    "        output_dir: 关键帧存放目录。\n",
    "        target_frames: 每个视频的关键帧数。\n",
    "        height: 每帧的高度。\n",
    "        width: 每帧的宽度。\n",
    "    Returns:\n",
    "        TensorFlow 数据集，元素为 (关键帧张量, 标签)。\n",
    "    \"\"\"\n",
    "    frames_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    # 遍历类别（标签）\n",
    "    for label in os.listdir(output_dir):\n",
    "        label_dir = os.path.join(output_dir, label).replace(\"\\\\\", \"/\")  # 统一为 /\n",
    "        if not os.path.isdir(label_dir):\n",
    "            continue\n",
    "        \n",
    "        # 遍历每个视频文件夹\n",
    "        for video_folder in os.listdir(label_dir):\n",
    "            video_dir = os.path.join(label_dir, video_folder).replace(\"\\\\\", \"/\")  # 统一为 /\n",
    "            if not os.path.isdir(video_dir):\n",
    "                continue\n",
    "            \n",
    "            # 获取所有帧路径\n",
    "            frame_paths = [\n",
    "                os.path.join(video_dir, frame).replace(\"\\\\\", \"/\")  # 统一为 /\n",
    "                for frame in os.listdir(video_dir)\n",
    "                if frame.endswith((\".jpg\", \".png\"))\n",
    "            ]\n",
    "            \n",
    "            # 跳过空视频文件夹\n",
    "            if not frame_paths:\n",
    "                print(f\"跳过空视频文件夹: {video_dir}\")\n",
    "                continue\n",
    "            \n",
    "            # 加载和预处理帧\n",
    "            frames = load_and_preprocess_frames(frame_paths, height, width, target_frames)\n",
    "            frames_list.append(frames)\n",
    "            labels_list.append(label)\n",
    "    \n",
    "    # 将标签转为整数索引\n",
    "    unique_labels = sorted(set(labels_list))\n",
    "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    labels_list = [label_to_index[label] for label in labels_list]\n",
    "    \n",
    "    # 转为 TensorFlow 数据集\n",
    "    frames_tensor = tf.convert_to_tensor(np.array(frames_list), dtype=tf.float32)\n",
    "    labels_tensor = tf.convert_to_tensor(np.array(labels_list), dtype=tf.int32)\n",
    "    return tf.data.Dataset.from_tensor_slices((frames_tensor, labels_tensor)), label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy.ndimage import sobel\n",
    "\n",
    "def load_and_preprocess_frames_custom(frame_paths, target_height, target_width, target_frames):\n",
    "    \"\"\"\n",
    "    加载帧并预处理为灰度 + 水平梯度 + 垂直梯度三通道，统一大小和数量。\n",
    "    \n",
    "    Args:\n",
    "        frame_paths: 帧文件路径列表。\n",
    "        target_height: 每帧的目标高度。\n",
    "        target_width: 每帧的目标宽度。\n",
    "        target_frames: 目标帧数。\n",
    "        \n",
    "    Returns:\n",
    "        三通道关键帧张量，形状为 (target_frames, height, width, 3)。\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for frame_path in sorted(frame_paths):  # 确保按时间顺序加载\n",
    "        # 加载图片并调整大小\n",
    "        image = Image.open(frame_path).convert('L')  # 转为灰度图\n",
    "        image = image.resize((target_width, target_height))\n",
    "        image_array = np.array(image, dtype=np.float32) / 255.0  # 归一化到 [0, 1]\n",
    "        \n",
    "        # 计算梯度通道\n",
    "        grad_x = sobel(image_array, axis=1)  # 水平方向梯度\n",
    "        grad_y = sobel(image_array, axis=0)  # 垂直方向梯度\n",
    "        \n",
    "        # 归一化梯度到 [0, 1]\n",
    "        grad_x = (grad_x - grad_x.min()) / (grad_x.max() - grad_x.min() + 1e-6)\n",
    "        grad_y = (grad_y - grad_y.min()) / (grad_y.max() - grad_y.min() + 1e-6)\n",
    "        \n",
    "        # 构造三通道图像\n",
    "        three_channel_frame = np.stack([image_array, grad_x, grad_y], axis=-1)\n",
    "        frames.append(three_channel_frame)\n",
    "\n",
    "    # 确保帧数量一致（补齐或裁剪）\n",
    "    if len(frames) > target_frames:\n",
    "        frames = frames[:target_frames]\n",
    "    elif len(frames) < target_frames:\n",
    "        padding = target_frames - len(frames)\n",
    "        padding_frame = np.zeros((target_height, target_width, 3))  # 零填充帧\n",
    "        frames.extend([padding_frame] * padding)\n",
    "\n",
    "    return np.stack(frames, axis=0)\n",
    "\n",
    "def create_custom_dataset(output_dir, target_frames, height, width):\n",
    "    \"\"\"\n",
    "    使用灰度 + 梯度三通道帧构建 TensorFlow 数据集。\n",
    "    \"\"\"\n",
    "    frames_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for label in os.listdir(output_dir):\n",
    "        label_dir = os.path.join(output_dir, label).replace(\"\\\\\", \"/\")\n",
    "        if not os.path.isdir(label_dir):\n",
    "            continue\n",
    "\n",
    "        for video_folder in os.listdir(label_dir):\n",
    "            video_dir = os.path.join(label_dir, video_folder).replace(\"\\\\\", \"/\")\n",
    "            if not os.path.isdir(video_dir):\n",
    "                continue\n",
    "\n",
    "            # 获取帧路径\n",
    "            frame_paths = [\n",
    "                os.path.join(video_dir, frame).replace(\"\\\\\", \"/\")\n",
    "                for frame in os.listdir(video_dir)\n",
    "                if frame.endswith((\".jpg\", \".png\"))\n",
    "            ]\n",
    "            if not frame_paths:\n",
    "                print(f\"跳过空视频文件夹: {video_dir}\")\n",
    "                continue\n",
    "\n",
    "            # 使用新的方法加载和处理帧\n",
    "            frames = load_and_preprocess_frames_custom(frame_paths, height, width, target_frames)\n",
    "            frames_list.append(frames)\n",
    "            labels_list.append(label)\n",
    "\n",
    "    # 转换标签\n",
    "    unique_labels = sorted(set(labels_list))\n",
    "    label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    labels_list = [label_to_index[label] for label in labels_list]\n",
    "\n",
    "    # 转为 TensorFlow 数据集\n",
    "    frames_tensor = tf.convert_to_tensor(np.array(frames_list), dtype=tf.float32)\n",
    "    labels_tensor = tf.convert_to_tensor(np.array(labels_list), dtype=tf.int32)\n",
    "    return tf.data.Dataset.from_tensor_slices((frames_tensor, labels_tensor)), label_to_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataset_from_frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 构建数据集\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset, label_map \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset_from_frames\u001b[49m(OUTPUT_DIR, TARGET_FRAMES, HEIGHT, WIDTH)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_dataset_from_frames' is not defined"
     ]
    }
   ],
   "source": [
    "# 构建数据集\n",
    "dataset, label_map = create_dataset_from_frames(OUTPUT_DIR, TARGET_FRAMES, HEIGHT, WIDTH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "跳过空视频文件夹: C:/data/result/scene_detector/0-两手托天理三焦（八段锦）/动作0-10-31\n",
      "帧形状: (20, 224, 224, 3), 标签: 0\n",
      "通道均值: [0.56452185 0.5130549  0.5523341 ]\n"
     ]
    }
   ],
   "source": [
    "dataset, label_map = create_custom_dataset(OUTPUT_DIR, TARGET_FRAMES, HEIGHT, WIDTH)\n",
    "\n",
    "# 查看一个样本\n",
    "for frames, label in dataset.take(1):\n",
    "    print(f\"帧形状: {frames.shape}, 标签: {label.numpy()}\")\n",
    "    print(f\"通道均值: {tf.reduce_mean(frames, axis=[0, 1, 2]).numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别映射表: {'0-两手托天理三焦（八段锦）': 0, '1-左右开弓似射雕（八段锦）': 1, '10鹿抵（五禽戏）': 2, '11鹿奔（五禽戏）': 3, '12鸟伸（五禽戏）': 4, '13鸟飞（五禽戏）': 5, '14其他': 6, '2-调理脾胃单臂举（八段锦）': 7, '3-五劳七伤往后瞧（八段锦）': 8, '4-摇头摆尾去心火（八段锦）': 9, '5-两手攀足固肾腰（八段锦）': 10, '6-攒拳怒目增气力（八段锦）': 11, '7背后七颠百病消（八段锦）': 12, '8虎举（五禽戏）': 13, '9虎扑（五禽戏）': 14}\n",
      "关键帧张量形状: (20, 224, 224)\n",
      "标签: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 打印类别映射表\n",
    "print(\"类别映射表:\", label_map)\n",
    "\n",
    "# 检查数据集\n",
    "for frames, label in dataset.take(1):\n",
    "    print(\"关键帧张量形状:\", frames.shape)  # 应该是 (20, 224, 224, 3)\n",
    "    print(\"标签:\", label.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def extract_labels_from_dataset(dataset):\n",
    "    \"\"\"\n",
    "    从 TensorFlow 数据集中提取所有唯一的标签。\n",
    "    \n",
    "    Args:\n",
    "        dataset: tf.data.Dataset 对象，包含 (frames_tensor, label_tensor)。\n",
    "    Returns:\n",
    "        标签的集合（去重）。\n",
    "    \"\"\"\n",
    "    labels = set()\n",
    "    for _, label in dataset:\n",
    "        labels.add(label.numpy())  # 将标签添加到集合中\n",
    "    return labels\n",
    "\n",
    "# 从已构建的数据集中提取标签\n",
    "all_labels = extract_labels_from_dataset(dataset)\n",
    "print(\"所有标签：\", all_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集已保存到: C:/data/result/saved_dataset_grey\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def save_dataset(dataset, save_path):\n",
    "    \"\"\"\n",
    "    使用最新方法保存 TensorFlow 数据集。\n",
    "    \n",
    "    Args:\n",
    "        dataset: tf.data.Dataset 对象。\n",
    "        save_path: 保存路径。\n",
    "    \"\"\"\n",
    "    dataset.save(save_path)\n",
    "    print(f\"数据集已保存到: {save_path}\")\n",
    "\n",
    "# 保存数据集\n",
    "save_path = \"C:/data/result/saved_dataset_grey\"\n",
    "save_dataset(dataset, save_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15516\\4248829838.py:12: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.load(...)` instead.\n",
      "数据集已从 C:/data/result/saved_dataset_grey 加载\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "save_path = \"C:/data/result/saved_dataset_grey\"\n",
    "def load_dataset(save_path):\n",
    "    \"\"\"\n",
    "    从指定路径加载 TensorFlow 数据集。\n",
    "    \n",
    "    Args:\n",
    "        save_path: 数据集保存路径。\n",
    "    Returns:\n",
    "        加载的 tf.data.Dataset 对象。\n",
    "    \"\"\"\n",
    "    dataset = tf.data.experimental.load(save_path)\n",
    "    print(f\"数据集已从 {save_path} 加载\")\n",
    "    return dataset\n",
    "\n",
    "# 加载数据集\n",
    "dataset = load_dataset(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后的标签分布: {0: 49, 1: 50, 2: 50, 3: 50, 4: 50, 5: 50, 6: 50, 7: 50, 8: 50, 9: 50, 10: 50, 11: 50, 12: 50, 13: 50}\n"
     ]
    }
   ],
   "source": [
    "def remove_last_label(dataset):\n",
    "    \"\"\"\n",
    "    从数据集中移除最后一个标签对应的所有数据。\n",
    "    \n",
    "    Args:\n",
    "        dataset: TensorFlow 数据集，元素为 (关键帧张量, 标签)。\n",
    "    Returns:\n",
    "        新的数据集，只包含不属于最后一个标签的数据。\n",
    "    \"\"\"\n",
    "    # 找到数据集中最大标签值（即最后一个标签的索引）\n",
    "    max_label = tf.reduce_max([label for _, label in dataset])\n",
    "\n",
    "    # 筛选出不属于最后一个标签的数据\n",
    "    filtered_dataset = dataset.filter(lambda x, y: y != max_label)\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "def reassign_dataset_with_filtered(dataset):\n",
    "    \"\"\"\n",
    "    清除原始 dataset 的引用，并将筛选后的 dataset 重新赋值为 dataset。\n",
    "    \n",
    "    Args:\n",
    "        dataset: 原始未筛选的数据集。\n",
    "    \n",
    "    Returns:\n",
    "        筛选后的数据集，赋值为 dataset。\n",
    "    \"\"\"\n",
    "    filtered_dataset = remove_last_label(dataset)\n",
    "    del dataset  # 清除原始数据集的引用\n",
    "    return filtered_dataset\n",
    "\n",
    "# 使用筛选后的数据集\n",
    "dataset = reassign_dataset_with_filtered(dataset)\n",
    "\n",
    "# 验证标签分布\n",
    "def print_filtered_labels_summary(dataset):\n",
    "    label_counts = {}\n",
    "    for _, label in dataset:\n",
    "        label = label.numpy()\n",
    "        if label not in label_counts:\n",
    "            label_counts[label] = 0\n",
    "        label_counts[label] += 1\n",
    "    print(f\"筛选后的标签分布: {label_counts}\")\n",
    "\n",
    "print_filtered_labels_summary(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 dataset 是已经处理好的 tf.data.Dataset 对象\n",
    "# 将 dataset 分为训练集和验证集\n",
    "train_split = 0.90  # 80% 数据用于训练\n",
    "val_split = 1 - train_split\n",
    "\n",
    "# 获取总样本数\n",
    "total_samples = len(list(dataset))\n",
    "train_size = int(total_samples * train_split)\n",
    "\n",
    "# 分割数据集\n",
    "train_ds = dataset.take(train_size)\n",
    "val_ds = dataset.skip(train_size)\n",
    "\n",
    "# 配置训练和验证集\n",
    "train_ds = train_ds.shuffle(buffer_size=1000).batch(8).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(8).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del dataset\n",
    "import gc\n",
    "gc.collect()  # 强制进行垃圾回收"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import numpy as np\n",
    "import remotezip as rz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras import layers\n",
    "# 启用 XLA\n",
    "tf.config.optimizer.set_jit(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import einops\n",
    "# 启用 XLA\n",
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# 定义生成的每一帧的尺寸\n",
    "HEIGHT = 224  # 高度为224像素\n",
    "WIDTH = 224   # 宽度为224像素\n",
    "class Conv2Plus1D(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding):\n",
    "        \"\"\"\n",
    "        一个卷积层的组合，首先对空间维度进行卷积操作，\n",
    "        然后对时间维度进行卷积操作。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([  \n",
    "            # 空间维度分解卷积\n",
    "            layers.Conv3D(filters=filters,\n",
    "                          kernel_size=(1, kernel_size[1], kernel_size[2]),  # 只对高度和宽度进行卷积\n",
    "                          padding=padding),\n",
    "            # 时间维度分解卷积\n",
    "            layers.Conv3D(filters=filters, \n",
    "                          kernel_size=(kernel_size[0], 1, 1),  # 只对时间步长进行卷积\n",
    "                          padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        # 执行序列化卷积操作\n",
    "        return self.seq(x)\n",
    "class ResidualMain(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    模型中的残差模块，包含卷积、层归一化和 ReLU 激活函数。\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([\n",
    "            # 第一个卷积层\n",
    "            Conv2Plus1D(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same'),\n",
    "            # 层归一化\n",
    "            layers.LayerNormalization(),\n",
    "            # ReLU 激活函数\n",
    "            layers.ReLU(),\n",
    "            # 第二个卷积层\n",
    "            Conv2Plus1D(filters=filters, \n",
    "                        kernel_size=kernel_size,\n",
    "                        padding='same'),\n",
    "            # 层归一化\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        # 执行序列化的操作\n",
    "        return self.seq(x)\n",
    "class Project(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    通过不同大小的过滤器和下采样，对张量的某些维度进行投影处理。\n",
    "    \"\"\"\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.seq = keras.Sequential([\n",
    "            # 全连接层（投影操作）\n",
    "            layers.Dense(units), \n",
    "            # 层归一化\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        # 执行顺序操作\n",
    "        return self.seq(x)\n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "  \"\"\"\n",
    "    Add residual blocks to the model. If the last dimensions of the input data\n",
    "    and filter size does not match, project it such that last dimension matches.\n",
    "  \"\"\"\n",
    "  out = ResidualMain(filters, \n",
    "                     kernel_size)(input)\n",
    "\n",
    "  res = input\n",
    "  # Using the Keras functional APIs, project the last dimension of the tensor to\n",
    "  # match the new filter size\n",
    "  if out.shape[-1] != input.shape[-1]:\n",
    "    res = Project(out.shape[-1])(res)\n",
    "\n",
    "  return layers.add([res, out])\n",
    "\n",
    "\n",
    "class ResizeVideo(keras.layers.Layer):\n",
    "    def __init__(self, height, width):\n",
    "        \"\"\"\n",
    "        初始化视频尺寸调整层。\n",
    "\n",
    "        Args:\n",
    "            height: 调整后的高度。\n",
    "            width: 调整后的宽度。\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        # 使用 Keras 的 Resizing 层来调整尺寸\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        \"\"\"\n",
    "        调整视频张量的尺寸。\n",
    "\n",
    "        Args:\n",
    "            video: 表示视频的张量，形状为 (batch, time, height, width, channels)。\n",
    "\n",
    "        Returns:\n",
    "            调整为新高度和宽度的视频张量。\n",
    "        \"\"\"\n",
    "        # 解析视频的原始形状：b 表示批次大小，t 表示时间步，h 和 w 表示高度和宽度，c 表示通道数\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "\n",
    "        # 将视频重新排列为单张图像的形式，合并批次和时间维度\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "\n",
    "        # 调整每一帧的尺寸\n",
    "        images = self.resizing_layer(images)\n",
    "\n",
    "        # 将调整后的图像重新排列为视频的形式，分离批次和时间维度\n",
    "        videos = einops.rearrange(\n",
    "            images, '(b t) h w c -> b t h w c',\n",
    "            t=old_shape['t']\n",
    "        )\n",
    "        return videos\n",
    "\n",
    "input_shape = (None, 20, HEIGHT, WIDTH, 3)  # 输入视频的形状，None 表示批次大小不固定\n",
    "input = layers.Input(shape=(input_shape[1:]))  # 定义输入层，形状为 (时间步数, 高度, 宽度, 通道数)\n",
    "x = input\n",
    "\n",
    "# 初始卷积层：执行 2+1D 卷积操作（空间 + 时间分解）\n",
    "x = Conv2Plus1D(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)  # 批量归一化层，规范化每批次的特征\n",
    "x = layers.ReLU()(x)  # 激活函数 ReLU\n",
    "x = ResizeVideo(HEIGHT//2, WIDTH//4 )(x)  # 调整视频帧的尺寸到 (HEIGHT/2, WIDTH/2)\n",
    "\n",
    "# Block 1: 添加第一个残差块并调整尺寸\n",
    "x = add_residual_block(x, 16, (3, 3, 3))  # 添加残差块，过滤器数为 16，卷积核大小为 3x3x3\n",
    "x = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)  # 调整尺寸到 (HEIGHT/4, WIDTH/4)\n",
    "\n",
    "# Block 2: 添加第二个残差块并调整尺寸\n",
    "x = add_residual_block(x, 32, (3, 3, 3))  # 过滤器数为 32\n",
    "x = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)  # 调整尺寸到 (HEIGHT/8, WIDTH/8)\n",
    "\n",
    "# Block 3: 添加第三个残差块并调整尺寸\n",
    "x = add_residual_block(x, 64, (3, 3, 3))  # 过滤器数为 64\n",
    "x = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)  # 调整尺寸到 (HEIGHT/16, WIDTH/16)\n",
    "\n",
    "# Block 4: 添加第四个残差块\n",
    "x = add_residual_block(x, 128, (3, 3, 3))  # 过滤器数为 128\n",
    "\n",
    "# 全局平均池化和分类\n",
    "x = layers.GlobalAveragePooling3D()(x)  # 对时间、空间维度进行全局平均池化，生成特征向量\n",
    "x = layers.Flatten()(x)  # 展平为 1D 向量\n",
    "x = layers.Dense(15)(x)  # 全连接层输出 10 个分类\n",
    "\n",
    "# 定义模型\n",
    "model = keras.Model(input, x)\n",
    "\n",
    "# 从训练数据集中获取一个批次的数据\n",
    "frames, label = next(iter(train_ds))\n",
    "\n",
    "# 通过 build 方法将模型与输入张量关联，用于可视化或调试\n",
    "model.build(frames)\n",
    "\n",
    "# 使用 Keras 提供的工具绘制模型结构\n",
    "keras.utils.plot_model(\n",
    "    model,               # 目标模型\n",
    "    expand_nested=True,  # 展开嵌套的层，例如子模块或自定义层\n",
    "    dpi=60,              # 设置图片分辨率\n",
    "    show_shapes=True     # 显示每一层输出的形状\n",
    ")\n",
    "\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # 使用稀疏分类交叉熵作为损失函数\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),              # 优化器为 Adam，学习率设置为 0.0001\n",
    "    metrics=['accuracy']                                               # 评估指标为准确率\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 113s 830ms/step - loss: 2.7243 - accuracy: 0.1219 - val_loss: 5.9379 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 98s 1s/step - loss: 2.3973 - accuracy: 0.1686 - val_loss: 6.1220 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 62s 680ms/step - loss: 2.3433 - accuracy: 0.1686 - val_loss: 6.6064 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 62s 680ms/step - loss: 2.2936 - accuracy: 0.1669 - val_loss: 6.9151 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 62s 680ms/step - loss: 2.2467 - accuracy: 0.1970 - val_loss: 7.2825 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 62s 684ms/step - loss: 2.2167 - accuracy: 0.1753 - val_loss: 7.2943 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 61s 670ms/step - loss: 2.1564 - accuracy: 0.2120 - val_loss: 7.6847 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 62s 680ms/step - loss: 2.1380 - accuracy: 0.2154 - val_loss: 7.3423 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 62s 677ms/step - loss: 2.0663 - accuracy: 0.2237 - val_loss: 7.7156 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 62s 681ms/step - loss: 2.0445 - accuracy: 0.2387 - val_loss: 7.4973 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 63s 688ms/step - loss: 2.0275 - accuracy: 0.2270 - val_loss: 7.9045 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 62s 683ms/step - loss: 1.9642 - accuracy: 0.2521 - val_loss: 7.6765 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 62s 681ms/step - loss: 1.9107 - accuracy: 0.2538 - val_loss: 8.1285 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 62s 680ms/step - loss: 1.8835 - accuracy: 0.2504 - val_loss: 9.3407 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 62s 685ms/step - loss: 1.8435 - accuracy: 0.2671 - val_loss: 8.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 61s 671ms/step - loss: 1.8860 - accuracy: 0.2621 - val_loss: 8.6862 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 61s 674ms/step - loss: 1.8173 - accuracy: 0.2821 - val_loss: 8.5151 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 62s 679ms/step - loss: 1.8023 - accuracy: 0.2972 - val_loss: 8.7057 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 62s 685ms/step - loss: 1.8103 - accuracy: 0.2738 - val_loss: 8.1784 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 62s 686ms/step - loss: 1.7542 - accuracy: 0.2888 - val_loss: 9.5892 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 62s 673ms/step - loss: 1.7353 - accuracy: 0.2955 - val_loss: 8.9810 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 62s 678ms/step - loss: 1.7238 - accuracy: 0.3172 - val_loss: 8.5325 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 62s 680ms/step - loss: 1.7294 - accuracy: 0.2988 - val_loss: 9.0310 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 62s 678ms/step - loss: 1.6960 - accuracy: 0.3038 - val_loss: 9.2147 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 62s 679ms/step - loss: 1.7008 - accuracy: 0.3222 - val_loss: 8.8492 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 62s 682ms/step - loss: 1.6719 - accuracy: 0.3289 - val_loss: 9.0622 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 62s 686ms/step - loss: 1.6476 - accuracy: 0.3506 - val_loss: 8.5338 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 62s 685ms/step - loss: 1.6956 - accuracy: 0.3122 - val_loss: 9.4057 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 60s 655ms/step - loss: 1.6478 - accuracy: 0.3356 - val_loss: 8.6386 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 61s 659ms/step - loss: 1.6250 - accuracy: 0.3673 - val_loss: 9.4162 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 61s 659ms/step - loss: 1.6382 - accuracy: 0.3606 - val_loss: 8.7726 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 60s 656ms/step - loss: 1.5961 - accuracy: 0.3806 - val_loss: 7.9125 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 61s 659ms/step - loss: 1.5929 - accuracy: 0.3823 - val_loss: 8.8214 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 60s 655ms/step - loss: 1.5924 - accuracy: 0.3840 - val_loss: 8.8475 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 60s 653ms/step - loss: 1.6351 - accuracy: 0.3506 - val_loss: 9.3563 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 60s 658ms/step - loss: 1.5406 - accuracy: 0.4407 - val_loss: 8.5073 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 61s 656ms/step - loss: 1.5043 - accuracy: 0.4174 - val_loss: 9.6910 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 60s 655ms/step - loss: 1.5358 - accuracy: 0.4107 - val_loss: 8.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 60s 655ms/step - loss: 1.4854 - accuracy: 0.4508 - val_loss: 9.3825 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 60s 650ms/step - loss: 1.4978 - accuracy: 0.4107 - val_loss: 8.2847 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 60s 653ms/step - loss: 1.4593 - accuracy: 0.4658 - val_loss: 10.2173 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 60s 653ms/step - loss: 1.4305 - accuracy: 0.4591 - val_loss: 10.2279 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 60s 656ms/step - loss: 1.4262 - accuracy: 0.4658 - val_loss: 9.9718 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 60s 656ms/step - loss: 1.3996 - accuracy: 0.4558 - val_loss: 8.9309 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 61s 667ms/step - loss: 1.3591 - accuracy: 0.5092 - val_loss: 9.6659 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 62s 680ms/step - loss: 1.3612 - accuracy: 0.4808 - val_loss: 10.3511 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 62s 682ms/step - loss: 1.3701 - accuracy: 0.4925 - val_loss: 9.7603 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 62s 677ms/step - loss: 1.3506 - accuracy: 0.4992 - val_loss: 10.0025 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 63s 689ms/step - loss: 1.3756 - accuracy: 0.4841 - val_loss: 8.8208 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 62s 679ms/step - loss: 1.3098 - accuracy: 0.5142 - val_loss: 9.9748 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_ds,            # 使用训练数据集\n",
    "    epochs=50,             # 训练 50 轮\n",
    "    validation_data=val_ds # 使用验证数据集\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 112\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_config\u001b[39m(\u001b[38;5;28mcls\u001b[39m, config):\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m--> 112\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m    113\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m    114\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class Conv2Plus1D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            layers.Conv3D(filters=filters, kernel_size=(1, kernel_size[1], kernel_size[2]), padding=padding),\n",
    "            layers.Conv3D(filters=filters, kernel_size=(kernel_size[0], 1, 1), padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        # 确保返回所有参数，包括自定义的\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'padding': self.padding\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # 通过从配置字典中解构来创建类实例\n",
    "        return cls(**config)\n",
    "\n",
    "class ResidualMain(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "class Project(layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            layers.Dense(units),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'units': self.units\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "class ResizeVideo(layers.Layer):\n",
    "    def __init__(self, height, width, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'height': self.height,\n",
    "            'width': self.width\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存到：C:\\data\\result\\model\\200grey_model.h5\n"
     ]
    }
   ],
   "source": [
    "# 假设您已有一个训练好的模型 'model'\n",
    "save_path =r'C:\\data\\result\\model\\200grey_model.h5'\n",
    "\n",
    "# 保存整个模型\n",
    "try:\n",
    "   # model.save_weights(save_path)\n",
    "    model.save(save_path)\n",
    "\n",
    "    print(f\"模型已保存到：{save_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"保存模型时发生错误: {e}\")\n",
    "\n",
    "\n",
    "#print(f\"模型已保存到：{save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "\nLayer Conv2Plus1D has arguments ['filters', 'kernel_size', 'padding']\nin `__init__` and therefore must override `get_config()`.\n\nExample:\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2):\n        super().__init__()\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 使用 Keras 原生格式保存模型\u001b[39;00m\n\u001b[0;32m      2\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbest_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m模型已保存到：\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\base_layer.py:786\u001b[0m, in \u001b[0;36mLayer.get_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;66;03m# Check that either the only argument in the `__init__` is  `self`,\u001b[39;00m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;66;03m# or that `get_config` has been overridden:\u001b[39;00m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_default\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    787\u001b[0m         textwrap\u001b[38;5;241m.\u001b[39mdedent(\n\u001b[0;32m    788\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;124m  Layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextra_args\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;124m  in `__init__` and therefore must override `get_config()`.\u001b[39m\n\u001b[0;32m    791\u001b[0m \n\u001b[0;32m    792\u001b[0m \u001b[38;5;124m  Example:\u001b[39m\n\u001b[0;32m    793\u001b[0m \n\u001b[0;32m    794\u001b[0m \u001b[38;5;124m  class CustomLayer(keras.layers.Layer):\u001b[39m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;124m      def __init__(self, arg1, arg2):\u001b[39m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;124m          super().__init__()\u001b[39m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;124m          self.arg1 = arg1\u001b[39m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;124m          self.arg2 = arg2\u001b[39m\n\u001b[0;32m    799\u001b[0m \n\u001b[0;32m    800\u001b[0m \u001b[38;5;124m      def get_config(self):\u001b[39m\n\u001b[0;32m    801\u001b[0m \u001b[38;5;124m          config = super().get_config()\u001b[39m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;124m          config.update(\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;124m              \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: self.arg1,\u001b[39m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;124m              \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg2\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: self.arg2,\u001b[39m\n\u001b[0;32m    805\u001b[0m \u001b[38;5;124m          \u001b[39m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;124m          return config\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    807\u001b[0m         )\n\u001b[0;32m    808\u001b[0m     )\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: \nLayer Conv2Plus1D has arguments ['filters', 'kernel_size', 'padding']\nin `__init__` and therefore must override `get_config()`.\n\nExample:\n\nclass CustomLayer(keras.layers.Layer):\n    def __init__(self, arg1, arg2):\n        super().__init__()\n        self.arg1 = arg1\n        self.arg2 = arg2\n\n    def get_config(self):\n        config = super().get_config()\n        config.update({\n            \"arg1\": self.arg1,\n            \"arg2\": self.arg2,\n        })\n        return config"
     ]
    }
   ],
   "source": [
    "# 使用 Keras 原生格式保存模型\n",
    "save_path = r'C:\\data\\result\\model\\best_model.keras'\n",
    "model.save(save_path)\n",
    "\n",
    "print(f\"模型已保存到：{save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 加载模型（如果是 .keras 格式）\n",
    "model_path = r'C:\\data\\result\\model\\best_model.keras'\n",
    "model = load_model(model_path)\n",
    "\n",
    "print(\"模型已成功加载！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "import einops\n",
    "\n",
    "# 定义自定义的 Conv2Plus1D 层，修改以接受 trainable 等参数\n",
    "class Conv2Plus1D(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding, **kwargs):\n",
    "        super().__init__(**kwargs)  # 接受所有传递给父类的参数，包括 trainable\n",
    "        self.seq = keras.Sequential([  \n",
    "            # 空间维度卷积\n",
    "            layers.Conv3D(filters=filters,\n",
    "                          kernel_size=(1, kernel_size[1], kernel_size[2]),\n",
    "                          padding=padding),\n",
    "            # 时间维度卷积\n",
    "            layers.Conv3D(filters=filters, \n",
    "                          kernel_size=(kernel_size[0], 1, 1),\n",
    "                          padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# 定义残差块的主要模块\n",
    "class ResidualMain(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super().__init__(**kwargs)  # 接受所有传递给父类的参数，包括 trainable\n",
    "        self.seq = keras.Sequential([\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# 定义用于投影的层\n",
    "class Project(keras.layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)  # 接受所有传递给父类的参数，包括 trainable\n",
    "        self.seq = keras.Sequential([\n",
    "            layers.Dense(units),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "# 定义 ResizeVideo 层，确保在加载时也能恢复参数\n",
    "class ResizeVideo(keras.layers.Layer):\n",
    "    def __init__(self, height, width, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(ResizeVideo, self).get_config()\n",
    "        config.update({\n",
    "            'height': self.height,\n",
    "            'width': self.width\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# 加载模型函数\n",
    "# 加载模型函数\n",
    "def load_my_model(model_path):\n",
    "    # 定义自定义层\n",
    "    custom_objects = {\n",
    "        'Conv2Plus1D': Conv2Plus1D,\n",
    "        'ResizeVideo': ResizeVideo,\n",
    "        'ResidualMain': ResidualMain,\n",
    "        'Project': Project  # 确保 Project 也被添加到 custom_objects 中\n",
    "    }\n",
    "    \n",
    "    # 使用 Keras 加载模型\n",
    "    model = load_model(model_path, custom_objects=custom_objects)\n",
    "    \n",
    "    # 编译模型\n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 调用加载模型的函数，假设您给的路径是 model_path\n",
    "model_path = r'C:\\data\\result\\model\\best_model.h5'  # 替换为您实际的模型文件路径\n",
    "model = load_my_model(model_path)\n",
    "\n",
    "# 可选：打印模型摘要\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r'C:\\data\\result\\model\\best_model.\n",
    "# 查看模型结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.models import load_model\n",
    "# 2. 编译模型（如果加载后没有编译，需要重新编译）\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00005),  # 初始学习率\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 3. 定义 ReduceLROnPlateau 回调来调整学习率\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',       # 监控验证集的损失\n",
    "    factor=0.5,               # 每次减小学习率的因子（例如，factor=0.5 表示每次学习率减半）\n",
    "    patience=3,               # 如果验证损失在 3 轮内没有改善，就减小学习率\n",
    "    min_lr=1e-6,              # 设置最小学习率\n",
    "    verbose=1                 # 输出学习率调整的日志\n",
    ")\n",
    "\n",
    "# 4. 继续训练模型\n",
    "history = model.fit(\n",
    "    x=train_ds,              # 训练数据集\n",
    "    epochs=20,               # 训练 50 轮，可以根据需要调整\n",
    "    validation_data=val_ds,  # 验证数据集\n",
    "    callbacks=[lr_scheduler] # 添加学习率调整回调\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新可以保存\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "import einops\n",
    "# 定义生成的每一帧的尺寸\n",
    "HEIGHT = 224  # 高度为224像素\n",
    "WIDTH = 224   # 宽度为224像素\n",
    "\n",
    "class Conv2Plus1D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.seq = tf.keras.Sequential([  \n",
    "            layers.Conv3D(filters=filters,\n",
    "                          kernel_size=(1, kernel_size[1], kernel_size[2]),  \n",
    "                          padding=padding),\n",
    "            layers.Conv3D(filters=filters, \n",
    "                          kernel_size=(kernel_size[0], 1, 1),  \n",
    "                          padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'padding': self.padding\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class ResidualMain(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class Project(layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            layers.Dense(units),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'units': self.units\n",
    "        })\n",
    "        return config\n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "  \"\"\"\n",
    "    Add residual blocks to the model. If the last dimensions of the input data\n",
    "    and filter size does not match, project it such that last dimension matches.\n",
    "  \"\"\"\n",
    "  out = ResidualMain(filters, \n",
    "                     kernel_size)(input)\n",
    "\n",
    "  res = input\n",
    "  # Using the Keras functional APIs, project the last dimension of the tensor to\n",
    "  # match the new filter size\n",
    "  if out.shape[-1] != input.shape[-1]:\n",
    "    res = Project(out.shape[-1])(res)\n",
    "\n",
    "  return layers.add([res, out])\n",
    "\n",
    "class ResizeVideo(layers.Layer):\n",
    "    def __init__(self, height, width, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'height': self.height,\n",
    "            'width': self.width\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# 保持原有的代码结构不变\n",
    "input_shape = (None, 20, HEIGHT, WIDTH, 3)  # 输入视频的形状\n",
    "input = layers.Input(shape=(input_shape[1:]))  # 输入层\n",
    "x = input\n",
    "\n",
    "# 初始卷积层\n",
    "x = Conv2Plus1D(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)  \n",
    "x = layers.ReLU()(x)  \n",
    "x = ResizeVideo(HEIGHT//2, WIDTH//4)(x)  \n",
    "\n",
    "# Block 1\n",
    "x = add_residual_block(x, 16, (3, 3, 3))  \n",
    "x = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)  \n",
    "\n",
    "# Block 2\n",
    "x = add_residual_block(x, 32, (3, 3, 3))  \n",
    "x = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)  \n",
    "\n",
    "# Block 3\n",
    "x = add_residual_block(x, 64, (3, 3, 3))  \n",
    "x = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)  \n",
    "\n",
    "# Block 4\n",
    "x = add_residual_block(x, 128, (3, 3, 3))  \n",
    "\n",
    "# 全局平均池化和分类\n",
    "x = layers.GlobalAveragePooling3D()(x)  \n",
    "x = layers.Flatten()(x)  \n",
    "x = layers.Dense(14)(x)  # 输出类别数为15\n",
    "\n",
    "# 添加Softmax层输出概率\n",
    "x = layers.Softmax()(x)  # Softmax层，输出概率\n",
    "\n",
    "# 定义模型\n",
    "model = tf.keras.Model(input, x)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # 设置from_logits=False，因为Softmax已被添加\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "79/79 [==============================] - 179s 2s/step - loss: 2.3668 - accuracy: 0.1669 - val_loss: 6.4392 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "79/79 [==============================] - 178s 2s/step - loss: 2.2939 - accuracy: 0.1955 - val_loss: 8.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "79/79 [==============================] - 179s 2s/step - loss: 2.2059 - accuracy: 0.2067 - val_loss: 7.3614 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "79/79 [==============================] - 180s 2s/step - loss: 2.1756 - accuracy: 0.2067 - val_loss: 7.3470 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "79/79 [==============================] - 169s 2s/step - loss: 2.1958 - accuracy: 0.2130 - val_loss: 10.6515 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 2.1155 - accuracy: 0.2178 - val_loss: 7.6117 - val_accuracy: 0.1286\n",
      "Epoch 7/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 2.0916 - accuracy: 0.2258 - val_loss: 6.9918 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 2.0774 - accuracy: 0.2289 - val_loss: 7.4385 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 2.0256 - accuracy: 0.2623 - val_loss: 7.4464 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 2.0020 - accuracy: 0.2417 - val_loss: 8.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.9239 - accuracy: 0.2734 - val_loss: 7.3530 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.9602 - accuracy: 0.2687 - val_loss: 7.8644 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 1.9122 - accuracy: 0.2734 - val_loss: 8.2627 - val_accuracy: 0.1000\n",
      "Epoch 14/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.8893 - accuracy: 0.2496 - val_loss: 8.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.8838 - accuracy: 0.2480 - val_loss: 7.4259 - val_accuracy: 0.2857\n",
      "Epoch 16/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 1.8220 - accuracy: 0.2734 - val_loss: 6.9471 - val_accuracy: 0.1429\n",
      "Epoch 17/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 1.8005 - accuracy: 0.2973 - val_loss: 8.1529 - val_accuracy: 0.0143\n",
      "Epoch 18/150\n",
      "79/79 [==============================] - 173s 2s/step - loss: 1.8072 - accuracy: 0.2957 - val_loss: 7.2671 - val_accuracy: 0.0143\n",
      "Epoch 19/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.7664 - accuracy: 0.3307 - val_loss: 8.4791 - val_accuracy: 0.0143\n",
      "Epoch 20/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 1.7826 - accuracy: 0.2830 - val_loss: 7.5479 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.7516 - accuracy: 0.3243 - val_loss: 7.5525 - val_accuracy: 0.0857\n",
      "Epoch 22/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 1.7315 - accuracy: 0.3148 - val_loss: 7.6997 - val_accuracy: 0.0143\n",
      "Epoch 23/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.7329 - accuracy: 0.3180 - val_loss: 7.5681 - val_accuracy: 0.0571\n",
      "Epoch 24/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 1.6988 - accuracy: 0.3291 - val_loss: 6.8025 - val_accuracy: 0.0857\n",
      "Epoch 25/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.7085 - accuracy: 0.3211 - val_loss: 7.8250 - val_accuracy: 0.0714\n",
      "Epoch 26/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.6640 - accuracy: 0.3466 - val_loss: 8.8103 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.6347 - accuracy: 0.3831 - val_loss: 6.5283 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.6181 - accuracy: 0.3959 - val_loss: 6.9986 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "79/79 [==============================] - 166s 2s/step - loss: 1.6238 - accuracy: 0.3672 - val_loss: 8.3416 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.6082 - accuracy: 0.3720 - val_loss: 7.6223 - val_accuracy: 0.0143\n",
      "Epoch 31/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.5906 - accuracy: 0.3609 - val_loss: 7.5278 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "79/79 [==============================] - 166s 2s/step - loss: 1.6173 - accuracy: 0.3641 - val_loss: 8.1283 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.5416 - accuracy: 0.3831 - val_loss: 7.3005 - val_accuracy: 0.0714\n",
      "Epoch 34/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.5403 - accuracy: 0.4070 - val_loss: 7.1623 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "79/79 [==============================] - 166s 2s/step - loss: 1.5135 - accuracy: 0.4277 - val_loss: 8.1989 - val_accuracy: 0.0143\n",
      "Epoch 36/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.5102 - accuracy: 0.4165 - val_loss: 7.5235 - val_accuracy: 0.0286\n",
      "Epoch 37/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.4859 - accuracy: 0.4404 - val_loss: 8.2972 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.4932 - accuracy: 0.4245 - val_loss: 7.4386 - val_accuracy: 0.0571\n",
      "Epoch 39/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.4571 - accuracy: 0.4563 - val_loss: 6.7681 - val_accuracy: 0.0429\n",
      "Epoch 40/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.4050 - accuracy: 0.4849 - val_loss: 7.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.4872 - accuracy: 0.4420 - val_loss: 7.1549 - val_accuracy: 0.1857\n",
      "Epoch 42/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.4193 - accuracy: 0.4722 - val_loss: 7.8004 - val_accuracy: 0.2286\n",
      "Epoch 43/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.4100 - accuracy: 0.4595 - val_loss: 9.3059 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.4265 - accuracy: 0.4436 - val_loss: 7.5614 - val_accuracy: 0.0143\n",
      "Epoch 45/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.3694 - accuracy: 0.4897 - val_loss: 8.2647 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.3392 - accuracy: 0.4897 - val_loss: 6.4702 - val_accuracy: 0.1000\n",
      "Epoch 47/150\n",
      "79/79 [==============================] - 166s 2s/step - loss: 1.3153 - accuracy: 0.5453 - val_loss: 6.7841 - val_accuracy: 0.1857\n",
      "Epoch 48/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.2997 - accuracy: 0.5246 - val_loss: 8.1122 - val_accuracy: 0.0143\n",
      "Epoch 49/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.2935 - accuracy: 0.5342 - val_loss: 7.0036 - val_accuracy: 0.1143\n",
      "Epoch 50/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.3061 - accuracy: 0.4944 - val_loss: 7.5897 - val_accuracy: 0.0714\n",
      "Epoch 51/150\n",
      "79/79 [==============================] - 166s 2s/step - loss: 1.2507 - accuracy: 0.5405 - val_loss: 7.4999 - val_accuracy: 0.1000\n",
      "Epoch 52/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.2176 - accuracy: 0.5517 - val_loss: 8.1363 - val_accuracy: 0.0857\n",
      "Epoch 53/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.3032 - accuracy: 0.5183 - val_loss: 8.7073 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.2424 - accuracy: 0.5501 - val_loss: 8.0017 - val_accuracy: 0.0571\n",
      "Epoch 55/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.1693 - accuracy: 0.5692 - val_loss: 7.2436 - val_accuracy: 0.1429\n",
      "Epoch 56/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.1698 - accuracy: 0.5866 - val_loss: 6.9484 - val_accuracy: 0.2286\n",
      "Epoch 57/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.2097 - accuracy: 0.5580 - val_loss: 7.7655 - val_accuracy: 0.1000\n",
      "Epoch 58/150\n",
      "79/79 [==============================] - 166s 2s/step - loss: 1.1423 - accuracy: 0.5994 - val_loss: 8.1448 - val_accuracy: 0.0857\n",
      "Epoch 59/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.1625 - accuracy: 0.5660 - val_loss: 7.9868 - val_accuracy: 0.1857\n",
      "Epoch 60/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.0839 - accuracy: 0.6184 - val_loss: 6.4159 - val_accuracy: 0.1286\n",
      "Epoch 61/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.0830 - accuracy: 0.5994 - val_loss: 7.4641 - val_accuracy: 0.1714\n",
      "Epoch 62/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.0558 - accuracy: 0.6439 - val_loss: 8.3836 - val_accuracy: 0.0857\n",
      "Epoch 63/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 1.0179 - accuracy: 0.6423 - val_loss: 7.2744 - val_accuracy: 0.1857\n",
      "Epoch 64/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.0184 - accuracy: 0.6343 - val_loss: 8.1885 - val_accuracy: 0.0571\n",
      "Epoch 65/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.0021 - accuracy: 0.6407 - val_loss: 6.9158 - val_accuracy: 0.0714\n",
      "Epoch 66/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.9774 - accuracy: 0.6630 - val_loss: 8.3399 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.9705 - accuracy: 0.6677 - val_loss: 7.6572 - val_accuracy: 0.1429\n",
      "Epoch 68/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.9669 - accuracy: 0.6852 - val_loss: 15.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.9858 - accuracy: 0.6677 - val_loss: 7.9600 - val_accuracy: 0.1000\n",
      "Epoch 70/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.9417 - accuracy: 0.6852 - val_loss: 6.8773 - val_accuracy: 0.1143\n",
      "Epoch 71/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.9645 - accuracy: 0.6566 - val_loss: 8.3188 - val_accuracy: 0.1286\n",
      "Epoch 72/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.9114 - accuracy: 0.7027 - val_loss: 7.9472 - val_accuracy: 0.1571\n",
      "Epoch 73/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.8558 - accuracy: 0.7218 - val_loss: 7.7987 - val_accuracy: 0.1714\n",
      "Epoch 74/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.8764 - accuracy: 0.7266 - val_loss: 8.2182 - val_accuracy: 0.1286\n",
      "Epoch 75/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.8558 - accuracy: 0.7266 - val_loss: 8.8634 - val_accuracy: 0.0143\n",
      "Epoch 76/150\n",
      "79/79 [==============================] - 166s 2s/step - loss: 0.8159 - accuracy: 0.7456 - val_loss: 8.0828 - val_accuracy: 0.0714\n",
      "Epoch 77/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.8238 - accuracy: 0.7393 - val_loss: 7.4041 - val_accuracy: 0.2000\n",
      "Epoch 78/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.8015 - accuracy: 0.7250 - val_loss: 7.4560 - val_accuracy: 0.1000\n",
      "Epoch 79/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.7914 - accuracy: 0.7536 - val_loss: 8.5383 - val_accuracy: 0.0571\n",
      "Epoch 80/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.7298 - accuracy: 0.7774 - val_loss: 7.8769 - val_accuracy: 0.1143\n",
      "Epoch 81/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.7536 - accuracy: 0.7774 - val_loss: 7.9383 - val_accuracy: 0.1714\n",
      "Epoch 82/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.7490 - accuracy: 0.7711 - val_loss: 8.5558 - val_accuracy: 0.1714\n",
      "Epoch 83/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.7150 - accuracy: 0.7774 - val_loss: 7.5050 - val_accuracy: 0.1429\n",
      "Epoch 84/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.6639 - accuracy: 0.8092 - val_loss: 7.3029 - val_accuracy: 0.1714\n",
      "Epoch 85/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.7131 - accuracy: 0.7838 - val_loss: 12.1145 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "79/79 [==============================] - 166s 2s/step - loss: 0.6802 - accuracy: 0.7981 - val_loss: 8.3297 - val_accuracy: 0.1143\n",
      "Epoch 87/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.6308 - accuracy: 0.8394 - val_loss: 7.5268 - val_accuracy: 0.1429\n",
      "Epoch 88/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.5954 - accuracy: 0.8521 - val_loss: 8.1325 - val_accuracy: 0.1857\n",
      "Epoch 89/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.6528 - accuracy: 0.8172 - val_loss: 7.7417 - val_accuracy: 0.1429\n",
      "Epoch 90/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.5872 - accuracy: 0.8347 - val_loss: 8.6019 - val_accuracy: 0.0857\n",
      "Epoch 91/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.5598 - accuracy: 0.8569 - val_loss: 8.1399 - val_accuracy: 0.1429\n",
      "Epoch 92/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.5376 - accuracy: 0.8601 - val_loss: 8.3396 - val_accuracy: 0.1286\n",
      "Epoch 93/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.5623 - accuracy: 0.8474 - val_loss: 8.4930 - val_accuracy: 0.1571\n",
      "Epoch 94/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.4987 - accuracy: 0.8633 - val_loss: 8.2128 - val_accuracy: 0.1571\n",
      "Epoch 95/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.5023 - accuracy: 0.8760 - val_loss: 7.9326 - val_accuracy: 0.2000\n",
      "Epoch 96/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.5170 - accuracy: 0.8665 - val_loss: 7.8124 - val_accuracy: 0.1714\n",
      "Epoch 97/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.4600 - accuracy: 0.8887 - val_loss: 8.5965 - val_accuracy: 0.1143\n",
      "Epoch 98/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.4710 - accuracy: 0.8808 - val_loss: 8.6617 - val_accuracy: 0.0714\n",
      "Epoch 99/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.4364 - accuracy: 0.9126 - val_loss: 8.8085 - val_accuracy: 0.1143\n",
      "Epoch 100/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.4062 - accuracy: 0.9189 - val_loss: 7.9352 - val_accuracy: 0.1429\n",
      "Epoch 101/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.5177 - accuracy: 0.8553 - val_loss: 8.2061 - val_accuracy: 0.1143\n",
      "Epoch 102/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.4398 - accuracy: 0.8903 - val_loss: 7.5823 - val_accuracy: 0.1429\n",
      "Epoch 103/150\n",
      "79/79 [==============================] - 166s 2s/step - loss: 0.3912 - accuracy: 0.9173 - val_loss: 7.6930 - val_accuracy: 0.1286\n",
      "Epoch 104/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.3623 - accuracy: 0.9221 - val_loss: 8.5871 - val_accuracy: 0.2000\n",
      "Epoch 105/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.3296 - accuracy: 0.9555 - val_loss: 8.0015 - val_accuracy: 0.2571\n",
      "Epoch 106/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.3479 - accuracy: 0.9348 - val_loss: 8.3893 - val_accuracy: 0.0429\n",
      "Epoch 107/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.3224 - accuracy: 0.9428 - val_loss: 8.3436 - val_accuracy: 0.2429\n",
      "Epoch 108/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.3300 - accuracy: 0.9396 - val_loss: 8.8516 - val_accuracy: 0.1857\n",
      "Epoch 109/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.3008 - accuracy: 0.9380 - val_loss: 8.2850 - val_accuracy: 0.1857\n",
      "Epoch 110/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.2714 - accuracy: 0.9714 - val_loss: 9.0000 - val_accuracy: 0.1429\n",
      "Epoch 111/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.2894 - accuracy: 0.9444 - val_loss: 8.1964 - val_accuracy: 0.2714\n",
      "Epoch 112/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.2504 - accuracy: 0.9587 - val_loss: 8.1921 - val_accuracy: 0.2286\n",
      "Epoch 113/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.2613 - accuracy: 0.9714 - val_loss: 8.6868 - val_accuracy: 0.1286\n",
      "Epoch 114/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.2759 - accuracy: 0.9412 - val_loss: 8.0664 - val_accuracy: 0.2286\n",
      "Epoch 115/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.2226 - accuracy: 0.9730 - val_loss: 8.6724 - val_accuracy: 0.1143\n",
      "Epoch 116/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.2587 - accuracy: 0.9555 - val_loss: 7.8221 - val_accuracy: 0.2000\n",
      "Epoch 117/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.2693 - accuracy: 0.9396 - val_loss: 7.8545 - val_accuracy: 0.2000\n",
      "Epoch 118/150\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.2180 - accuracy: 0.9730 - val_loss: 8.3098 - val_accuracy: 0.2143\n",
      "Epoch 119/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1923 - accuracy: 0.9762 - val_loss: 8.8812 - val_accuracy: 0.2286\n",
      "Epoch 120/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1805 - accuracy: 0.9825 - val_loss: 8.3529 - val_accuracy: 0.2000\n",
      "Epoch 121/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.2112 - accuracy: 0.9714 - val_loss: 9.2783 - val_accuracy: 0.2571\n",
      "Epoch 122/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.2195 - accuracy: 0.9634 - val_loss: 9.2181 - val_accuracy: 0.2286\n",
      "Epoch 123/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.2255 - accuracy: 0.9603 - val_loss: 8.4940 - val_accuracy: 0.1429\n",
      "Epoch 124/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.2692 - accuracy: 0.9300 - val_loss: 9.0422 - val_accuracy: 0.2000\n",
      "Epoch 125/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.2006 - accuracy: 0.9714 - val_loss: 9.9907 - val_accuracy: 0.2286\n",
      "Epoch 126/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.2171 - accuracy: 0.9650 - val_loss: 8.9126 - val_accuracy: 0.1000\n",
      "Epoch 127/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.1763 - accuracy: 0.9777 - val_loss: 9.2061 - val_accuracy: 0.2143\n",
      "Epoch 128/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1331 - accuracy: 0.9889 - val_loss: 9.2176 - val_accuracy: 0.2000\n",
      "Epoch 129/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1128 - accuracy: 0.9968 - val_loss: 9.2730 - val_accuracy: 0.1714\n",
      "Epoch 130/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.1104 - accuracy: 0.9968 - val_loss: 9.0960 - val_accuracy: 0.1429\n",
      "Epoch 131/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1498 - accuracy: 0.9777 - val_loss: 9.5842 - val_accuracy: 0.2143\n",
      "Epoch 132/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1445 - accuracy: 0.9809 - val_loss: 9.9876 - val_accuracy: 0.2286\n",
      "Epoch 133/150\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.1447 - accuracy: 0.9857 - val_loss: 9.5011 - val_accuracy: 0.2000\n",
      "Epoch 134/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1043 - accuracy: 0.9905 - val_loss: 9.6806 - val_accuracy: 0.0429\n",
      "Epoch 135/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0862 - accuracy: 0.9984 - val_loss: 8.9963 - val_accuracy: 0.2143\n",
      "Epoch 136/150\n",
      "79/79 [==============================] - 170s 2s/step - loss: 0.1054 - accuracy: 0.9825 - val_loss: 9.0718 - val_accuracy: 0.1143\n",
      "Epoch 137/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1526 - accuracy: 0.9746 - val_loss: 9.6349 - val_accuracy: 0.1571\n",
      "Epoch 138/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1757 - accuracy: 0.9666 - val_loss: 9.2106 - val_accuracy: 0.1286\n",
      "Epoch 139/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.2823 - accuracy: 0.9221 - val_loss: 10.6748 - val_accuracy: 0.1286\n",
      "Epoch 140/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1525 - accuracy: 0.9682 - val_loss: 10.1371 - val_accuracy: 0.1571\n",
      "Epoch 141/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0744 - accuracy: 0.9968 - val_loss: 9.0612 - val_accuracy: 0.1857\n",
      "Epoch 142/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0592 - accuracy: 1.0000 - val_loss: 9.4635 - val_accuracy: 0.2143\n",
      "Epoch 143/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.1002 - accuracy: 0.9905 - val_loss: 9.4740 - val_accuracy: 0.2286\n",
      "Epoch 144/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.0787 - accuracy: 0.9936 - val_loss: 9.3640 - val_accuracy: 0.1857\n",
      "Epoch 145/150\n",
      "79/79 [==============================] - 167s 2s/step - loss: 0.0721 - accuracy: 0.9936 - val_loss: 9.1547 - val_accuracy: 0.2143\n",
      "Epoch 146/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0870 - accuracy: 0.9936 - val_loss: 9.9549 - val_accuracy: 0.2286\n",
      "Epoch 147/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0745 - accuracy: 0.9984 - val_loss: 9.2352 - val_accuracy: 0.1286\n",
      "Epoch 148/150\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.1262 - accuracy: 0.9777 - val_loss: 11.7052 - val_accuracy: 0.0571\n",
      "Epoch 149/150\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.1000 - accuracy: 0.9825 - val_loss: 9.9576 - val_accuracy: 0.1286\n",
      "Epoch 150/150\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0643 - accuracy: 0.9968 - val_loss: 9.4725 - val_accuracy: 0.1714\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_ds,            # 使用训练数据集\n",
    "    epochs=150,             # 训练 50 轮\n",
    "    validation_data=val_ds # 使用验证数据集\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "85/85 [==============================] - 68s 648ms/step - loss: 0.6901 - accuracy: 0.8042 - val_loss: 16.1734 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/25\n",
      "85/85 [==============================] - 68s 654ms/step - loss: 0.6871 - accuracy: 0.7982 - val_loss: 8.0698 - val_accuracy: 0.0267\n",
      "Epoch 3/25\n",
      "85/85 [==============================] - 68s 658ms/step - loss: 0.6826 - accuracy: 0.7878 - val_loss: 10.2522 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/25\n",
      "85/85 [==============================] - 68s 653ms/step - loss: 0.6030 - accuracy: 0.8516 - val_loss: 8.5674 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/25\n",
      "85/85 [==============================] - 68s 653ms/step - loss: 0.6713 - accuracy: 0.8145 - val_loss: 9.1816 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/25\n",
      "85/85 [==============================] - 68s 651ms/step - loss: 0.6181 - accuracy: 0.8398 - val_loss: 8.7538 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/25\n",
      "85/85 [==============================] - 68s 653ms/step - loss: 0.5935 - accuracy: 0.8398 - val_loss: 9.7279 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/25\n",
      "85/85 [==============================] - 68s 651ms/step - loss: 0.5654 - accuracy: 0.8487 - val_loss: 9.0783 - val_accuracy: 0.1600\n",
      "Epoch 9/25\n",
      "85/85 [==============================] - 68s 648ms/step - loss: 0.5620 - accuracy: 0.8457 - val_loss: 11.6181 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/25\n",
      "85/85 [==============================] - 67s 646ms/step - loss: 0.5893 - accuracy: 0.8249 - val_loss: 11.5289 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/25\n",
      "85/85 [==============================] - 68s 651ms/step - loss: 0.5566 - accuracy: 0.8472 - val_loss: 12.7743 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/25\n",
      "85/85 [==============================] - 69s 660ms/step - loss: 0.5199 - accuracy: 0.8739 - val_loss: 9.9782 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/25\n",
      "85/85 [==============================] - 68s 656ms/step - loss: 0.5145 - accuracy: 0.8576 - val_loss: 8.2700 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/25\n",
      "85/85 [==============================] - 68s 655ms/step - loss: 0.5086 - accuracy: 0.8694 - val_loss: 8.6679 - val_accuracy: 0.2533\n",
      "Epoch 15/25\n",
      "85/85 [==============================] - 69s 660ms/step - loss: 0.5290 - accuracy: 0.8620 - val_loss: 9.2086 - val_accuracy: 0.0267\n",
      "Epoch 16/25\n",
      "85/85 [==============================] - 68s 653ms/step - loss: 0.4542 - accuracy: 0.8887 - val_loss: 9.4805 - val_accuracy: 0.0133\n",
      "Epoch 17/25\n",
      "85/85 [==============================] - 68s 655ms/step - loss: 0.4578 - accuracy: 0.8828 - val_loss: 9.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/25\n",
      "85/85 [==============================] - 68s 653ms/step - loss: 0.4815 - accuracy: 0.8783 - val_loss: 8.9074 - val_accuracy: 0.1733\n",
      "Epoch 19/25\n",
      "85/85 [==============================] - 69s 662ms/step - loss: 0.4925 - accuracy: 0.8531 - val_loss: 9.6751 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/25\n",
      "85/85 [==============================] - 68s 654ms/step - loss: 0.4262 - accuracy: 0.8843 - val_loss: 11.0594 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/25\n",
      "85/85 [==============================] - 68s 656ms/step - loss: 0.4154 - accuracy: 0.9080 - val_loss: 9.5512 - val_accuracy: 0.0667\n",
      "Epoch 22/25\n",
      "85/85 [==============================] - 68s 653ms/step - loss: 0.4123 - accuracy: 0.9154 - val_loss: 8.8824 - val_accuracy: 0.2267\n",
      "Epoch 23/25\n",
      "85/85 [==============================] - 68s 651ms/step - loss: 0.4448 - accuracy: 0.8843 - val_loss: 9.0258 - val_accuracy: 0.0533\n",
      "Epoch 24/25\n",
      "85/85 [==============================] - 68s 646ms/step - loss: 0.4153 - accuracy: 0.8872 - val_loss: 9.5011 - val_accuracy: 0.0267\n",
      "Epoch 25/25\n",
      "85/85 [==============================] - 68s 651ms/step - loss: 0.3846 - accuracy: 0.9228 - val_loss: 9.5995 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_ds,            # 使用训练数据集\n",
    "    epochs=25,             # 训练 50 轮\n",
    "    validation_data=val_ds # 使用验证数据集\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "85/85 [==============================] - 80s 687ms/step - loss: 0.2955 - accuracy: 0.9570 - val_loss: 9.2853 - val_accuracy: 0.0533\n",
      "Epoch 2/50\n",
      "85/85 [==============================] - 75s 735ms/step - loss: 0.2822 - accuracy: 0.9644 - val_loss: 9.1893 - val_accuracy: 0.1067\n",
      "Epoch 3/50\n",
      "85/85 [==============================] - 67s 640ms/step - loss: 0.2782 - accuracy: 0.9688 - val_loss: 9.4427 - val_accuracy: 0.1067\n",
      "Epoch 4/50\n",
      "85/85 [==============================] - 68s 646ms/step - loss: 0.2732 - accuracy: 0.9674 - val_loss: 9.4592 - val_accuracy: 0.1200\n",
      "Epoch 5/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2690 - accuracy: 0.9688 - val_loss: 9.3873 - val_accuracy: 0.0667\n",
      "Epoch 6/50\n",
      "85/85 [==============================] - 66s 625ms/step - loss: 0.2630 - accuracy: 0.9748 - val_loss: 9.6784 - val_accuracy: 0.1333\n",
      "Epoch 7/50\n",
      "85/85 [==============================] - 65s 622ms/step - loss: 0.2626 - accuracy: 0.9718 - val_loss: 9.7526 - val_accuracy: 0.0800\n",
      "Epoch 8/50\n",
      "85/85 [==============================] - 65s 620ms/step - loss: 0.2592 - accuracy: 0.9703 - val_loss: 9.6336 - val_accuracy: 0.0800\n",
      "Epoch 9/50\n",
      "85/85 [==============================] - 65s 624ms/step - loss: 0.2581 - accuracy: 0.9733 - val_loss: 9.5342 - val_accuracy: 0.1067\n",
      "Epoch 10/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2518 - accuracy: 0.9777 - val_loss: 9.7062 - val_accuracy: 0.0800\n",
      "Epoch 11/50\n",
      "85/85 [==============================] - 66s 624ms/step - loss: 0.2532 - accuracy: 0.9733 - val_loss: 9.5859 - val_accuracy: 0.1467\n",
      "Epoch 12/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2482 - accuracy: 0.9777 - val_loss: 9.6883 - val_accuracy: 0.1200\n",
      "Epoch 13/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2535 - accuracy: 0.9703 - val_loss: 9.8132 - val_accuracy: 0.0667\n",
      "Epoch 14/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2413 - accuracy: 0.9792 - val_loss: 9.7399 - val_accuracy: 0.0800\n",
      "Epoch 15/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2495 - accuracy: 0.9688 - val_loss: 9.5858 - val_accuracy: 0.1200\n",
      "Epoch 16/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2473 - accuracy: 0.9733 - val_loss: 9.7753 - val_accuracy: 0.0800\n",
      "Epoch 17/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2373 - accuracy: 0.9822 - val_loss: 9.9825 - val_accuracy: 0.0667\n",
      "Epoch 18/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2379 - accuracy: 0.9792 - val_loss: 9.8492 - val_accuracy: 0.1200\n",
      "Epoch 19/50\n",
      "85/85 [==============================] - 65s 625ms/step - loss: 0.2350 - accuracy: 0.9837 - val_loss: 10.2266 - val_accuracy: 0.0667\n",
      "Epoch 20/50\n",
      "85/85 [==============================] - 66s 625ms/step - loss: 0.2309 - accuracy: 0.9837 - val_loss: 9.6600 - val_accuracy: 0.1733\n",
      "Epoch 21/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2349 - accuracy: 0.9807 - val_loss: 9.7258 - val_accuracy: 0.0933\n",
      "Epoch 22/50\n",
      "85/85 [==============================] - 66s 622ms/step - loss: 0.2288 - accuracy: 0.9792 - val_loss: 10.0264 - val_accuracy: 0.0800\n",
      "Epoch 23/50\n",
      "85/85 [==============================] - 65s 622ms/step - loss: 0.2335 - accuracy: 0.9763 - val_loss: 9.9964 - val_accuracy: 0.0267\n",
      "Epoch 24/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2258 - accuracy: 0.9777 - val_loss: 10.0129 - val_accuracy: 0.1067\n",
      "Epoch 25/50\n",
      "85/85 [==============================] - 66s 624ms/step - loss: 0.2213 - accuracy: 0.9866 - val_loss: 10.1971 - val_accuracy: 0.0667\n",
      "Epoch 26/50\n",
      "85/85 [==============================] - 66s 624ms/step - loss: 0.2294 - accuracy: 0.9733 - val_loss: 10.0086 - val_accuracy: 0.0800\n",
      "Epoch 27/50\n",
      "85/85 [==============================] - 65s 620ms/step - loss: 0.2270 - accuracy: 0.9777 - val_loss: 9.7533 - val_accuracy: 0.0933\n",
      "Epoch 28/50\n",
      "85/85 [==============================] - 65s 624ms/step - loss: 0.2191 - accuracy: 0.9837 - val_loss: 9.9433 - val_accuracy: 0.1200\n",
      "Epoch 29/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2164 - accuracy: 0.9777 - val_loss: 9.9394 - val_accuracy: 0.0933\n",
      "Epoch 30/50\n",
      "85/85 [==============================] - 65s 625ms/step - loss: 0.2186 - accuracy: 0.9792 - val_loss: 10.0557 - val_accuracy: 0.1067\n",
      "Epoch 31/50\n",
      "85/85 [==============================] - 66s 624ms/step - loss: 0.2163 - accuracy: 0.9852 - val_loss: 9.9565 - val_accuracy: 0.1200\n",
      "Epoch 32/50\n",
      "85/85 [==============================] - 65s 622ms/step - loss: 0.2171 - accuracy: 0.9822 - val_loss: 10.0243 - val_accuracy: 0.1067\n",
      "Epoch 33/50\n",
      "85/85 [==============================] - 65s 620ms/step - loss: 0.2192 - accuracy: 0.9792 - val_loss: 9.8252 - val_accuracy: 0.1333\n",
      "Epoch 34/50\n",
      "85/85 [==============================] - 66s 625ms/step - loss: 0.2111 - accuracy: 0.9807 - val_loss: 9.9770 - val_accuracy: 0.0933\n",
      "Epoch 35/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2147 - accuracy: 0.9792 - val_loss: 10.0775 - val_accuracy: 0.0667\n",
      "Epoch 36/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2086 - accuracy: 0.9881 - val_loss: 10.0234 - val_accuracy: 0.0933\n",
      "Epoch 37/50\n",
      "85/85 [==============================] - 66s 625ms/step - loss: 0.2058 - accuracy: 0.9852 - val_loss: 10.3859 - val_accuracy: 0.0667\n",
      "Epoch 38/50\n",
      "85/85 [==============================] - 66s 625ms/step - loss: 0.2086 - accuracy: 0.9822 - val_loss: 9.9131 - val_accuracy: 0.1067\n",
      "Epoch 39/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.2007 - accuracy: 0.9852 - val_loss: 10.1354 - val_accuracy: 0.0933\n",
      "Epoch 40/50\n",
      "85/85 [==============================] - 66s 627ms/step - loss: 0.1970 - accuracy: 0.9852 - val_loss: 9.9737 - val_accuracy: 0.0533\n",
      "Epoch 41/50\n",
      "85/85 [==============================] - 65s 622ms/step - loss: 0.2035 - accuracy: 0.9852 - val_loss: 10.0112 - val_accuracy: 0.0933\n",
      "Epoch 42/50\n",
      "85/85 [==============================] - 66s 624ms/step - loss: 0.1939 - accuracy: 0.9866 - val_loss: 10.2048 - val_accuracy: 0.0800\n",
      "Epoch 43/50\n",
      "85/85 [==============================] - 65s 619ms/step - loss: 0.2029 - accuracy: 0.9807 - val_loss: 10.1410 - val_accuracy: 0.0667\n",
      "Epoch 44/50\n",
      "85/85 [==============================] - 66s 624ms/step - loss: 0.1996 - accuracy: 0.9822 - val_loss: 9.9997 - val_accuracy: 0.0667\n",
      "Epoch 45/50\n",
      "85/85 [==============================] - 66s 624ms/step - loss: 0.2020 - accuracy: 0.9763 - val_loss: 10.1757 - val_accuracy: 0.1200\n",
      "Epoch 46/50\n",
      "85/85 [==============================] - 66s 624ms/step - loss: 0.1937 - accuracy: 0.9866 - val_loss: 10.2379 - val_accuracy: 0.0533\n",
      "Epoch 47/50\n",
      "85/85 [==============================] - 65s 622ms/step - loss: 0.1953 - accuracy: 0.9822 - val_loss: 9.8693 - val_accuracy: 0.1067\n",
      "Epoch 48/50\n",
      "85/85 [==============================] - 66s 624ms/step - loss: 0.1917 - accuracy: 0.9881 - val_loss: 10.4596 - val_accuracy: 0.0667\n",
      "Epoch 49/50\n",
      "85/85 [==============================] - 65s 620ms/step - loss: 0.1886 - accuracy: 0.9881 - val_loss: 10.2412 - val_accuracy: 0.0533\n",
      "Epoch 50/50\n",
      "85/85 [==============================] - 65s 624ms/step - loss: 0.1912 - accuracy: 0.9866 - val_loss: 10.3944 - val_accuracy: 0.0933\n"
     ]
    }
   ],
   "source": [
    "# 编译模型\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # 设置from_logits=False，因为Softmax已被添加\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    x=train_ds,            # 使用训练数据集\n",
    "    epochs=50,             # 训练 50 轮\n",
    "    validation_data=val_ds # 使用验证数据集\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "79/79 [==============================] - 180s 2s/step - loss: 0.0458 - accuracy: 0.9984 - val_loss: 9.4671 - val_accuracy: 0.1571\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0373 - accuracy: 0.9968 - val_loss: 9.4303 - val_accuracy: 0.1571\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 9.4527 - val_accuracy: 0.1571\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0343 - accuracy: 0.9984 - val_loss: 9.4281 - val_accuracy: 0.1571\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0319 - accuracy: 0.9984 - val_loss: 9.4597 - val_accuracy: 0.1714\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0407 - accuracy: 0.9984 - val_loss: 9.4364 - val_accuracy: 0.1714\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 9.4254 - val_accuracy: 0.1714\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0376 - accuracy: 0.9984 - val_loss: 9.3683 - val_accuracy: 0.1714\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 9.3873 - val_accuracy: 0.1714\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 9.4370 - val_accuracy: 0.1714\n",
      "Epoch 11/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0303 - accuracy: 1.0000 - val_loss: 9.4378 - val_accuracy: 0.1714\n",
      "Epoch 12/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 9.4299 - val_accuracy: 0.1714\n",
      "Epoch 13/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 9.4266 - val_accuracy: 0.1714\n",
      "Epoch 14/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0314 - accuracy: 0.9984 - val_loss: 9.4531 - val_accuracy: 0.1714\n",
      "Epoch 15/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 9.4486 - val_accuracy: 0.1714\n",
      "Epoch 16/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 9.4520 - val_accuracy: 0.1714\n",
      "Epoch 17/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0330 - accuracy: 0.9968 - val_loss: 9.4878 - val_accuracy: 0.1714\n",
      "Epoch 18/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0300 - accuracy: 0.9984 - val_loss: 9.5066 - val_accuracy: 0.1714\n",
      "Epoch 19/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0307 - accuracy: 0.9984 - val_loss: 9.4677 - val_accuracy: 0.1714\n",
      "Epoch 20/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 9.4825 - val_accuracy: 0.1714\n",
      "Epoch 21/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 9.5192 - val_accuracy: 0.1714\n",
      "Epoch 22/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 9.4880 - val_accuracy: 0.1714\n",
      "Epoch 23/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 9.4689 - val_accuracy: 0.1714\n",
      "Epoch 24/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 9.4948 - val_accuracy: 0.1714\n",
      "Epoch 25/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 9.4980 - val_accuracy: 0.1714\n",
      "Epoch 26/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 9.5355 - val_accuracy: 0.1714\n",
      "Epoch 27/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 9.5204 - val_accuracy: 0.1714\n",
      "Epoch 28/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 9.5559 - val_accuracy: 0.1714\n",
      "Epoch 29/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 9.5068 - val_accuracy: 0.1714\n",
      "Epoch 30/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 9.5132 - val_accuracy: 0.1714\n",
      "Epoch 31/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 9.5327 - val_accuracy: 0.1714\n",
      "Epoch 32/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 9.5423 - val_accuracy: 0.1714\n",
      "Epoch 33/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 9.5547 - val_accuracy: 0.1714\n",
      "Epoch 34/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 9.5666 - val_accuracy: 0.1714\n",
      "Epoch 35/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 9.5302 - val_accuracy: 0.1714\n",
      "Epoch 36/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 9.5522 - val_accuracy: 0.1714\n",
      "Epoch 37/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 9.5144 - val_accuracy: 0.1714\n",
      "Epoch 38/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 9.4748 - val_accuracy: 0.1714\n",
      "Epoch 39/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 9.5109 - val_accuracy: 0.1714\n",
      "Epoch 40/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 9.5114 - val_accuracy: 0.1714\n",
      "Epoch 41/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 9.4948 - val_accuracy: 0.1714\n",
      "Epoch 42/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 9.5723 - val_accuracy: 0.1714\n",
      "Epoch 43/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 9.5612 - val_accuracy: 0.1714\n",
      "Epoch 44/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 9.5776 - val_accuracy: 0.1714\n",
      "Epoch 45/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 9.5582 - val_accuracy: 0.1714\n",
      "Epoch 46/50\n",
      "79/79 [==============================] - 168s 2s/step - loss: 0.0272 - accuracy: 0.9984 - val_loss: 9.5288 - val_accuracy: 0.1714\n",
      "Epoch 47/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0275 - accuracy: 0.9984 - val_loss: 9.5748 - val_accuracy: 0.1714\n",
      "Epoch 48/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0285 - accuracy: 0.9984 - val_loss: 9.5706 - val_accuracy: 0.1714\n",
      "Epoch 49/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 9.5696 - val_accuracy: 0.1714\n",
      "Epoch 50/50\n",
      "79/79 [==============================] - 169s 2s/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 9.6201 - val_accuracy: 0.1714\n"
     ]
    }
   ],
   "source": [
    "# 编译模型\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),  # 设置from_logits=False，因为Softmax已被添加\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.000001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    x=train_ds,            # 使用训练数据集\n",
    "    epochs=50,             # 训练 50 轮\n",
    "    validation_data=val_ds # 使用验证数据集\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_and_preprocess_frames(frame_paths, target_height, target_width, target_frames):\n",
    "    \"\"\"\n",
    "    从帧路径加载关键帧并预处理为固定大小和数量。\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for frame_path in sorted(frame_paths):  # 确保按帧序排列\n",
    "        image = Image.open(frame_path)\n",
    "        image = image.resize((target_width, target_height))  # 调整大小\n",
    "        frames.append(np.array(image) / 255.0)  # 归一化到 [0, 1]\n",
    "    \n",
    "    # 确保帧数量一致（补齐或裁剪）\n",
    "    if len(frames) > target_frames:\n",
    "        frames = frames[:target_frames]\n",
    "    elif len(frames) < target_frames:\n",
    "        padding = target_frames - len(frames)\n",
    "        frames.extend([np.zeros((target_height, target_width, 3))] * padding)  # 补零帧\n",
    "    \n",
    "    return np.stack(frames, axis=0)\n",
    "\n",
    "def predict_from_folder(model, folder_path, target_height, target_width, target_frames):\n",
    "    \"\"\"\n",
    "    用模型预测某文件夹中20帧视频的标签概率。\n",
    "    \"\"\"\n",
    "    # 获取帧路径\n",
    "    frame_paths = [\n",
    "        os.path.join(folder_path, frame).replace(\"\\\\\", \"/\")  # 统一为 /\n",
    "        for frame in os.listdir(folder_path)\n",
    "        if frame.endswith((\".jpg\", \".png\"))\n",
    "    ]\n",
    "    if not frame_paths:\n",
    "        raise ValueError(f\"文件夹 {folder_path} 中没有有效帧文件\")\n",
    "    \n",
    "    # 预处理帧\n",
    "    input_frames = load_and_preprocess_frames(frame_paths, target_height, target_width, target_frames)\n",
    "    input_frames = np.expand_dims(input_frames, axis=0)  # 添加批次维度\n",
    "    \n",
    "    # 预测\n",
    "    probabilities = model.predict(input_frames)\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "模型预测的各个标签概率分布: [2.8525180e-09 3.6167891e-03 1.3197482e-01 6.6177256e-02 3.4500619e-03\n",
      " 6.3217543e-05 2.9748273e-03 2.9127113e-08 2.7660965e-08 7.9162389e-01\n",
      " 2.7017288e-06 1.1617964e-04 1.1569661e-09 2.0664370e-09 1.4175920e-07]\n",
      "预测的类别索引: 9\n"
     ]
    }
   ],
   "source": [
    "folder_path = r\"c:\\data\\result\\scene_detector\\4-摇头摆尾去心火（八段锦）\\reference_4\"\n",
    "\n",
    "# 确保以下参数与模型一致\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "FRAMES = 20\n",
    "\n",
    "# 预测\n",
    "probabilities = predict_from_folder(model, folder_path, HEIGHT, WIDTH, FRAMES)\n",
    "print(\"模型预测的各个标签概率分布:\", probabilities[0])\n",
    "print(\"预测的类别索引:\", np.argmax(probabilities[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
