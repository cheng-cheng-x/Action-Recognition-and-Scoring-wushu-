{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 检查 CUDA 是否可用\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# 检查当前的 CUDA 设备数量\n",
    "print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "\n",
    "# 如果 CUDA 可用，输出当前使用的设备\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def check_cuda_installation():\n",
    "    # 检查 nvcc 版本 (CUDA 编译器)\n",
    "    try:\n",
    "        nvcc_version = subprocess.check_output(['nvcc', '--version']).decode('utf-8')\n",
    "        print(\"nvcc version:\\n\", nvcc_version)\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvcc is not found in PATH. Please ensure CUDA is installed and added to PATH.\")\n",
    "\n",
    "check_cuda_installation()\n",
    "\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version supported by PyTorch: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"PyTorch is not detecting CUDA.\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def check_nvidia_smi():\n",
    "    try:\n",
    "        result = subprocess.check_output(['nvidia-smi']).decode('utf-8')\n",
    "        print(\"nvidia-smi output:\\n\", result)\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvidia-smi is not found. Make sure NVIDIA drivers are installed correctly.\")\n",
    "\n",
    "check_nvidia_smi()\n",
    "\n",
    "import torch\n",
    "\n",
    "def check_torch_cuda():\n",
    "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "    print(f\"Number of CUDA devices: {torch.cuda.device_count()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "        print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "\n",
    "check_torch_cuda()\n",
    "\n",
    "import os\n",
    "\n",
    "def check_env_variables():\n",
    "    cuda_home = os.environ.get('CUDA_HOME', None)\n",
    "    path = os.environ.get('PATH', None)\n",
    "    print(f\"CUDA_HOME: {cuda_home}\")\n",
    "    print(f\"PATH includes CUDA: {'CUDA' in path}\")\n",
    "\n",
    "check_env_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version supported by PyTorch: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"PyTorch is not detecting CUDA.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def check_nvidia_smi():\n",
    "    try:\n",
    "        result = subprocess.check_output(['nvidia-smi']).decode('utf-8')\n",
    "        print(\"nvidia-smi output:\\n\", result)\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvidia-smi is not found. Make sure NVIDIA drivers are installed correctly.\")\n",
    "\n",
    "check_nvidia_smi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def check_env_variables():\n",
    "    cuda_home = os.environ.get('CUDA_HOME', None)\n",
    "    path = os.environ.get('PATH', None)\n",
    "    print(f\"CUDA_HOME: {cuda_home}\")\n",
    "    print(f\"PATH includes CUDA: {'CUDA' in path}\")\n",
    "\n",
    "check_env_variables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 加载 YOLOv5 模型\n",
    "#model = YOLO('yolov5s.pt')  # 加载预训练的 yolov5s 模型\n",
    "model = YOLO('yolov5n.pt')  # YOLOv5 Nano 模型\n",
    "\n",
    "\n",
    "# 输入视频路径\n",
    "video_path = r'C:\\data\\video\\0-两手托天理三焦（八段锦）\\standard_0.mp4'\n",
    "output_path = r'C:\\data\\result\\YOLO\\output_video.mp4'\n",
    "\n",
    "# 打开视频文件\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 获取视频的帧宽度、高度和帧率\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 定义视频编写器\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 设置输出格式为MP4\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 使用 YOLOv5 进行人体检测\n",
    "    results = model(frame, stream=True)  # stream=True 会逐帧处理，适合处理视频\n",
    "\n",
    "    # 绘制检测结果（边界框和标签）\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # 边界框坐标\n",
    "            conf = box.conf[0]  # 置信度\n",
    "            cls = box.cls[0]  # 类别\n",
    "            \n",
    "            if conf > 0.5 and int(cls) == 0:  # 只显示置信度大于0.5且类别为“人”（类别ID 0）\n",
    "                label = f'Person {conf:.2f}'\n",
    "                # 绘制边界框\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                # 显示标签\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # 将处理后的视频帧写入文件\n",
    "    out.write(frame)\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"处理后的视频已保存至: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "# 检查 CUDA 是否可用\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 加载 YOLOv5 Nano 模型并指定设备（GPU 或 CPU）\n",
    "model = YOLO('yolov5nu.pt').to(device)\n",
    "\n",
    "# 输入视频路径\n",
    "video_path = r'C:\\data\\video\\0-两手托天理三焦（八段锦）\\standard_0.mp4'\n",
    "output_path = r'C:\\data\\result\\YOLO\\output_video.mp4'\n",
    "\n",
    "# 打开视频文件\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 获取视频的帧宽度、高度和帧率\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 定义视频编写器\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 设置输出格式为MP4\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 使用 YOLOv5 进行人体检测，输入图像需要指定设备\n",
    "    results = model(frame, stream=True, device=device)\n",
    "\n",
    "    # 绘制检测结果（边界框和标签）\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # 边界框坐标\n",
    "            conf = box.conf[0]  # 置信度\n",
    "            cls = box.cls[0]  # 类别\n",
    "            \n",
    "            if conf > 0.5 and int(cls) == 0:  # 只显示置信度大于0.5且类别为“人”（类别ID 0）\n",
    "                label = f'Person {conf:.2f}'\n",
    "                # 绘制边界框\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                # 显示标签\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # 将处理后的视频帧写入文件\n",
    "    out.write(frame)\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"处理后的视频已保存至: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "# MobilePose 模型下载链接\n",
    "url = \"https://github.com/edvardHua/PoseEstimationForMobile/archive/refs/heads/master.zip\"\n",
    "output_dir = \"MobilePose\"\n",
    "\n",
    "# 如果目录不存在，则创建\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# 下载文件\n",
    "model_path = os.path.join(output_dir, \"MobilePose.zip\")\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"正在下载 MobilePose 模型...\")\n",
    "    urllib.request.urlretrieve(url, model_path)\n",
    "    print(\"MobilePose 模型下载完成!\")\n",
    "else:\n",
    "    print(\"MobilePose 模型已经存在.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "# 解压缩下载的 MobilePose 模型\n",
    "with zipfile.ZipFile(model_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(output_dir)\n",
    "\n",
    "print(\"MobilePose 模型已解压!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "\n",
    "# 加载 YOLOv5 模型\n",
    "model = YOLO('yolov5nu.pt')\n",
    "\n",
    "# 加载 MobilePose 模型\n",
    "model_path = r'C:\\Users\\Administrator\\Desktop\\code\\YOLO\\MobilePose\\PoseEstimationForMobile-master\\path_to_model.pth'\n",
    "pose_model = torch.load(model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pose_model.eval()\n",
    "\n",
    "# 输入视频路径\n",
    "video_path = r'C:\\data\\video\\your_video.mp4'\n",
    "output_path = r'C:\\data\\result\\YOLO\\output_video.mp4'\n",
    "\n",
    "# 打开视频文件\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 获取视频信息\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 定义视频编写器\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLOv5 人体检测\n",
    "    results = model(frame, stream=True)\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # YOLO 检测到的边界框\n",
    "            conf = box.conf[0]  # 置信度\n",
    "            cls = box.cls[0]  # 类别\n",
    "\n",
    "            if conf > 0.5 and int(cls) == 0:  # 只处理类别为“人”的检测结果\n",
    "                # 使用 MobilePose 检测关键点\n",
    "                keypoints = infer_pose(frame, [x1, y1, x2, y2], pose_model)\n",
    "\n",
    "                # 在帧上绘制关键点\n",
    "                for (x, y) in keypoints:\n",
    "                    cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)  # 绘制关键点\n",
    "\n",
    "    # 将处理后的视频帧写入文件\n",
    "    out.write(frame)\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"处理后的视频已保存至: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
