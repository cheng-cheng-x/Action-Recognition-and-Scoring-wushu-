{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/service/video/test1.mp4\n",
      "/home/service/video/test2.mp4\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# 读取视频路径\n",
    "def get_video_paths(directory):\n",
    "    video_extensions = ['*.mp4', '*.avi', '*.mov', '*.mkv', '*.flv']\n",
    "    video_paths = []\n",
    "    \n",
    "    for ext in video_extensions:\n",
    "        video_paths.extend(glob.glob(os.path.join(directory, ext)))  # 获取视频路径\n",
    "        \n",
    "    # 替换路径中的反斜杠为正斜杠\n",
    "    video_paths = [video.replace(\"\\\\\", \"/\") for video in video_paths]\n",
    "    \n",
    "    return video_paths\n",
    "\n",
    "# 使用示例\n",
    "video_directory = '/home/service/video'  # 路径可以直接使用正斜杠\n",
    "video_files = get_video_paths(video_directory)\n",
    "\n",
    "# 输出视频文件路径\n",
    "for video in video_files:\n",
    "    print(video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/service/video\\test1.mp4\n",
      "/home/service/video\\test2.mp4\n"
     ]
    }
   ],
   "source": [
    "# 使用示例\n",
    "video_directory = '/home/service/video'\n",
    "video_files = get_video_paths(video_directory)\n",
    "\n",
    "# 输出视频文件路径\n",
    "for video in video_files:\n",
    "    print(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 获取视频的基本信息\n",
    "def get_video_info(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    info = {\n",
    "        \"frame_count\": int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
    "        \"fps\": cap.get(cv2.CAP_PROP_FPS),\n",
    "        \"width\": int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        \"height\": int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    }\n",
    "    cap.release()\n",
    "    return info\n",
    "\n",
    "# 计算帧间光流\n",
    "def calculate_optical_flow(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    last_frame = None\n",
    "    frame_info = []\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_number = int(cap.get(cv2.CAP_PROP_POS_FRAMES) - 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.resize(gray, (320, 180))  # 减小分辨率加速处理\n",
    "\n",
    "        if last_frame is not None:\n",
    "            flow = cv2.calcOpticalFlowFarneback(\n",
    "                last_frame, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0\n",
    "            )\n",
    "            magnitude = np.sqrt(flow[..., 0]**2 + flow[..., 1]**2)\n",
    "            avg_magnitude = np.mean(magnitude)\n",
    "            frame_info.append({\n",
    "                \"frame_number\": frame_number,\n",
    "                \"optical_flow_mag\": avg_magnitude\n",
    "            })\n",
    "        last_frame = gray\n",
    "\n",
    "    cap.release()\n",
    "    return frame_info\n",
    "\n",
    "# K-Means 聚类帧\n",
    "def cluster_frames_kmeans(frame_info, n_clusters=20):\n",
    "    frame_numbers = np.array([f[\"frame_number\"] for f in frame_info])\n",
    "    optical_flows = np.array([f[\"optical_flow_mag\"] for f in frame_info])\n",
    "\n",
    "    # 特征矩阵：时间（帧号）和光流强度\n",
    "    features = np.column_stack((frame_numbers, optical_flows))\n",
    "\n",
    "    # 进行 K-Means 聚类\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(features)\n",
    "\n",
    "    # 将帧按聚类标签分组\n",
    "    clusters = {i: [] for i in range(n_clusters)}\n",
    "    for idx, label in enumerate(kmeans.labels_):\n",
    "        clusters[label].append(frame_info[idx])\n",
    "\n",
    "    # 为每类选择中心点帧\n",
    "    cluster_centers = kmeans.cluster_centers_\n",
    "    representative_frames = []\n",
    "    for cluster_id, center in enumerate(cluster_centers):\n",
    "        closest_frame = min(\n",
    "            clusters[cluster_id],\n",
    "            key=lambda x: np.linalg.norm([x[\"frame_number\"], x[\"optical_flow_mag\"]] - center)\n",
    "        )\n",
    "        representative_frames.append(closest_frame)\n",
    "\n",
    "    # 按时间顺序排序\n",
    "    representative_frames.sort(key=lambda x: x[\"frame_number\"])\n",
    "    return representative_frames\n",
    "\n",
    "# 获取视频的20个关键帧\n",
    "def get_20_key_frames(video_path):\n",
    "    # 获取视频的基本信息\n",
    "    video_info = get_video_info(video_path)\n",
    "    \n",
    "    # 获取光流信息\n",
    "    frame_info = calculate_optical_flow(video_path)\n",
    "    \n",
    "    # 进行K-Means聚类\n",
    "    representative_frames = cluster_frames_kmeans(frame_info, n_clusters=20)\n",
    "    \n",
    "    # 从视频中提取关键帧图像\n",
    "    key_frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    for frame_info in representative_frames:\n",
    "        frame_number = frame_info[\"frame_number\"]\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            key_frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    return key_frames\n",
    "\n",
    "# 使用示例\n",
    "video_path = '/home/service/video/test1.mp4'\n",
    "key_frames = get_20_key_frames(video_path)\n",
    "\n",
    "# key_frames 现在是包含20个关键帧的列表（不保存到硬盘，只在内存中）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_frames_from_videos(video_files):\n",
    "    all_key_frames = []  # 用于存储所有视频的关键帧\n",
    "    \n",
    "    for video in video_files:\n",
    "        key_frames = get_20_key_frames(video)  # 提取当前视频的关键帧\n",
    "        all_key_frames.extend(key_frames)  # 将当前视频的关键帧合并到总列表\n",
    "    \n",
    "    return all_key_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of key frames extracted: 40\n"
     ]
    }
   ],
   "source": [
    "# 假设你已经获取了视频路径列表\n",
    "video_files = get_video_paths(video_directory)\n",
    "\n",
    "# 提取所有视频的关键帧\n",
    "all_key_frames = extract_key_frames_from_videos(video_files)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"Total number of key frames extracted: {len(all_key_frames)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import einops\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "# 启用 XLA\n",
    "tf.config.optimizer.set_jit(True)\n",
    "TARGET_FRAMES = 20  # 每个视频的关键帧数\n",
    "HEIGHT, WIDTH = 224, 224  # 每帧的大小\n",
    "class Conv2Plus1D(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, padding, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            layers.Conv3D(filters=filters, kernel_size=(1, kernel_size[1], kernel_size[2]), padding=padding),\n",
    "            layers.Conv3D(filters=filters, kernel_size=(kernel_size[0], 1, 1), padding=padding)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        # 确保返回所有参数，包括自定义的\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size,\n",
    "            'padding': self.padding\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # 通过从配置字典中解构来创建类实例\n",
    "        return cls(**config)\n",
    "\n",
    "class ResidualMain(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization(),\n",
    "            layers.ReLU(),\n",
    "            Conv2Plus1D(filters=filters, kernel_size=kernel_size, padding='same'),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'filters': self.filters,\n",
    "            'kernel_size': self.kernel_size\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "def add_residual_block(input, filters, kernel_size):\n",
    "  \"\"\"\n",
    "    Add residual blocks to the model. If the last dimensions of the input data\n",
    "    and filter size does not match, project it such that last dimension matches.\n",
    "  \"\"\"\n",
    "  out = ResidualMain(filters, \n",
    "                     kernel_size)(input)\n",
    "\n",
    "  res = input\n",
    "  # Using the Keras functional APIs, project the last dimension of the tensor to\n",
    "  # match the new filter size\n",
    "  if out.shape[-1] != input.shape[-1]:\n",
    "    res = Project(out.shape[-1])(res)\n",
    "\n",
    "  return layers.add([res, out])\n",
    "\n",
    "\n",
    "class Project(layers.Layer):\n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            layers.Dense(units),\n",
    "            layers.LayerNormalization()\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.seq(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'units': self.units\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "class ResizeVideo(layers.Layer):\n",
    "    def __init__(self, height, width, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "    def call(self, video):\n",
    "        old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "        images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "        images = self.resizing_layer(images)\n",
    "        videos = einops.rearrange(images, '(b t) h w c -> b t h w c', t=old_shape['t'])\n",
    "        return videos\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'height': self.height,\n",
    "            'width': self.width\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "input_shape = (None, 20, HEIGHT, WIDTH, 3)  # 输入视频的形状，None 表示批次大小不固定\n",
    "input = layers.Input(shape=(input_shape[1:]))  # 定义输入层，形状为 (时间步数, 高度, 宽度, 通道数)\n",
    "x = input\n",
    "\n",
    "# 初始卷积层：执行 2+1D 卷积操作（空间 + 时间分解）\n",
    "x = Conv2Plus1D(filters=16, kernel_size=(3, 7, 7), padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)  # 批量归一化层，规范化每批次的特征\n",
    "x = layers.ReLU()(x)  # 激活函数 ReLU\n",
    "x = ResizeVideo(HEIGHT//2, WIDTH//4 )(x)  # 调整视频帧的尺寸到 (HEIGHT/2, WIDTH/2)\n",
    "\n",
    "# Block 1: 添加第一个残差块并调整尺寸\n",
    "x = add_residual_block(x, 16, (3, 3, 3))  # 添加残差块，过滤器数为 16，卷积核大小为 3x3x3\n",
    "x = ResizeVideo(HEIGHT // 4, WIDTH // 4)(x)  # 调整尺寸到 (HEIGHT/4, WIDTH/4)\n",
    "\n",
    "# Block 2: 添加第二个残差块并调整尺寸\n",
    "x = add_residual_block(x, 32, (3, 3, 3))  # 过滤器数为 32\n",
    "x = ResizeVideo(HEIGHT // 8, WIDTH // 8)(x)  # 调整尺寸到 (HEIGHT/8, WIDTH/8)\n",
    "\n",
    "# Block 3: 添加第三个残差块并调整尺寸\n",
    "x = add_residual_block(x, 64, (3, 3, 3))  # 过滤器数为 64\n",
    "x = ResizeVideo(HEIGHT // 16, WIDTH // 16)(x)  # 调整尺寸到 (HEIGHT/16, WIDTH/16)\n",
    "\n",
    "# Block 4: 添加第四个残差块\n",
    "x = add_residual_block(x, 128, (3, 3, 3))  # 过滤器数为 128\n",
    "\n",
    "# 全局平均池化和分类\n",
    "x = layers.GlobalAveragePooling3D()(x)  # 对时间、空间维度进行全局平均池化，生成特征向量\n",
    "x = layers.Flatten()(x)  # 展平为 1D 向量\n",
    "x = layers.Dense(15)(x)  # 全连接层输出 10 个分类\n",
    "\n",
    "# 定义模型\n",
    "model = keras.Model(input, x)\n",
    "# 修改损失函数的 reduction 参数\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False, reduction='sum_over_batch_size')\n",
    "# 使用 Keras 提供的工具绘制模型结构\n",
    "keras.utils.plot_model(\n",
    "    model,               # 目标模型\n",
    "    expand_nested=True,  # 展开嵌套的层，例如子模块或自定义层\n",
    "    dpi=60,              # 设置图片分辨率\n",
    "    show_shapes=True     # 显示每一层输出的形状\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 加载模型函数\n",
    "def load_my_model(model_path):\n",
    "    # 定义自定义层\n",
    "    custom_objects = {\n",
    "        'Conv2Plus1D': Conv2Plus1D,\n",
    "        'ResizeVideo': ResizeVideo,\n",
    "        'ResidualMain': ResidualMain,\n",
    "        'Project': Project  # 确保 Project 也被添加到 custom_objects 中\n",
    "    }\n",
    "    \n",
    "    # 使用 Keras 加载模型\n",
    "    model = load_model(model_path, custom_objects=custom_objects)\n",
    "    \n",
    "    # 编译模型\n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用加载模型的函数，假设您给的路径是 model_path\n",
    "model_path = r'C:\\data\\result\\model\\200grey_model.h5'  # 替换为您实际的模型文件路径\n",
    "model1 = load_my_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "def preprocess_frames(frames, target_height, target_width, target_frames):\n",
    "    \"\"\"\n",
    "    从帧数组加载关键帧并预处理为固定大小和数量。\n",
    "    \"\"\"\n",
    "    processed_frames = []\n",
    "    \n",
    "    for frame in frames:\n",
    "        # 调整大小\n",
    "        image = Image.fromarray(frame)\n",
    "        image = image.resize((target_width, target_height))  # 调整大小\n",
    "        processed_frames.append(np.array(image) / 255.0)  # 归一化到 [0, 1]\n",
    "    \n",
    "    # 确保帧数量一致（补齐或裁剪）\n",
    "    if len(processed_frames) > target_frames:\n",
    "        processed_frames = processed_frames[:target_frames]\n",
    "    elif len(processed_frames) < target_frames:\n",
    "        padding = target_frames - len(processed_frames)\n",
    "        processed_frames.extend([np.zeros((target_height, target_width, 3))] * padding)  # 补零帧\n",
    "    \n",
    "    return np.stack(processed_frames, axis=0)\n",
    "\n",
    "def predict_from_frames(model, frames, target_height, target_width, target_frames):\n",
    "    \"\"\"\n",
    "    用模型预测包含20帧的视频的标签概率。\n",
    "    \"\"\"\n",
    "    # 预处理帧\n",
    "    input_frames = preprocess_frames(frames, target_height, target_width, target_frames)\n",
    "    input_frames = np.expand_dims(input_frames, axis=0)  # 添加批次维度\n",
    "    \n",
    "    # 预测\n",
    "    probabilities = model.predict(input_frames)\n",
    "    return probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型加载成功！\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model2 = load_model(\"c:/data/result/model/final_model.h5\")\n",
    "model3=load_model(\"c:/data/result/model/score/best_model.h5\")\n",
    "print(\"模型加载成功！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n",
      "[[1.0980063e-07 4.2940484e-04 7.2821237e-02 4.5197557e-05 2.3340603e-05\n",
      "  6.4729804e-01 2.7894664e-01 6.9328891e-08 7.9848643e-09 4.3475602e-04\n",
      "  2.4451585e-10 4.0485414e-08 5.8735561e-10 1.1124544e-06]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "video_files = get_video_paths(video_directory)\n",
    "video_path=video_files[0]\n",
    "key_frames = get_20_key_frames(video_path)\n",
    "# 确保以下参数与模型一致\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "FRAMES = 20\n",
    "# 假设 model 是一个训练好的模型\n",
    "probabilities = predict_from_frames(model, key_frames, target_height=224, target_width=224, target_frames=20)\n",
    "\n",
    "prediction1 = model2.predict(probabilities)\n",
    "prediction2 = model3.predict(probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.5787441e-03, 1.7831551e-02, 4.3464056e-04, 1.7113968e-03,\n",
       "        7.5761862e-03, 1.1946023e-03, 2.6260444e-04, 2.4959608e-03,\n",
       "        9.3867995e-02, 1.2850942e-02, 1.5083400e-03, 2.0563640e-04,\n",
       "        3.2081397e-03, 8.4782982e-01, 1.4434474e-03]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1 = model2.predict(probabilities)\n",
    "prediction1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.607489]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "prediction2 = model3.predict(probabilities)\n",
    "prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "video_directory = '/home/service/video'\n",
    "# 假设这里是你处理文件的函数，模型的预测逻辑\n",
    "def process_file(file_path, model1, model2, model3):\n",
    "    # 获取文件名\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    # 假设你已经获取到视频的帧数据\n",
    "    key_frames = get_20_key_frames(file_path)\n",
    "    \n",
    "    # 获取prediction1 (标签)\n",
    "    probabilities = predict_from_frames(model1, key_frames, target_height=224, target_width=224, target_frames=20)\n",
    "    prediction1 = np.argmax(model2.predict(probabilities))  # 得到标签\n",
    "    \n",
    "    # 获取prediction2 (分数)\n",
    "    prediction2 = model3.predict(probabilities)[0][0]\n",
    "    \n",
    "    # 如果标签是14，设置prediction2为0\n",
    "    if prediction1 == 14:\n",
    "        prediction2 = 0\n",
    "    \n",
    "    return file_name, prediction1, prediction2\n",
    "\n",
    "# 全局变量，用来存储所有文件的结果\n",
    "all_file_results = []\n",
    "\n",
    "# 假设你有多个文件路径\n",
    "file_paths = get_video_paths(video_directory)\n",
    "\n",
    "# 处理每个文件\n",
    "for file_path in file_paths:\n",
    "    start_time = time.time()  # 记录处理开始时间\n",
    "    file_name, prediction1, prediction2 = process_file(file_path, model1, model2, model3)\n",
    "    end_time = time.time()  # 记录处理结束时间\n",
    "    \n",
    "    # 计算时间差（单位为毫秒）\n",
    "    time_taken_ms = (end_time - start_time) * 1000\n",
    "    \n",
    "    # 将结果添加到全局变量中\n",
    "    all_file_results.append({\n",
    "        \"file_name\": file_name,\n",
    "        \"prediction1\": prediction1,\n",
    "        \"prediction2\": prediction2,\n",
    "        \"time_taken_ms\": time_taken_ms\n",
    "    })\n",
    "\n",
    "output_directory = \"c:/15209917996_作品\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "output_file = os.path.join(output_directory, \"15209917996_submit.csv\")\n",
    "\n",
    "# 写入CSV文件\n",
    "with open(output_file, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    # 写入表头\n",
    "    writer.writerow([\"视频文件唯一标识\", \"动作分类标签label\", \"动作标准度评分\", \"推理总耗时(ms)\"])\n",
    "    \n",
    "    # 写入每个文件的结果\n",
    "    for result in all_file_results:\n",
    "        writer.writerow([\n",
    "            result[\"file_name\"],\n",
    "            result[\"prediction1\"],\n",
    "            result[\"prediction2\"],\n",
    "            result[\"time_taken_ms\"]\n",
    "        ])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
